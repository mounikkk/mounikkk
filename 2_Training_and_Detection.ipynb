{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mounikkk/mounikkk/blob/main/2_Training_and_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUANWN3rpfC9"
      },
      "source": [
        "# 0. Setup Paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2_E2TzlFhl1",
        "outputId": "d91c5cfa-8e41-4260-be29-87c69edd5abd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "146BB11JpfDA"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42hJEdo_pfDB"
      },
      "outputs": [],
      "source": [
        "CUSTOM_MODEL_NAME = 'my_faster_rcnn'\n",
        "PRETRAINED_MODEL_NAME = 'faster_rcnn_resnet152_v1_640x640_coco17_tpu-8'\n",
        "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet152_v1_640x640_coco17_tpu-8.tar.gz'\n",
        "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
        "LABEL_MAP_NAME = 'label_map.pbtxt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hbPhYVy_pfDB"
      },
      "outputs": [],
      "source": [
        "paths = {\n",
        "    'WORKSPACE_PATH': os.path.join('drive','MyDrive','Tensorflow', 'workspace'),\n",
        "    'SCRIPTS_PATH': os.path.join('drive','MyDrive','Tensorflow','scripts'),\n",
        "    'APIMODEL_PATH': os.path.join('drive','MyDrive','Tensorflow','models'),\n",
        "    'ANNOTATION_PATH': os.path.join('drive','MyDrive','Tensorflow', 'workspace','annotations'),\n",
        "    'IMAGE_PATH': os.path.join('drive','MyDrive','Tensorflow', 'workspace','images'),\n",
        "    'TRAIN_PATH': os.path.join('drive','MyDrive','Tensorflow', 'workspace','images','train'),\n",
        "    'MODEL_PATH': os.path.join('drive','MyDrive','Tensorflow', 'workspace','models2'),\n",
        "    'PRETRAINED_MODEL_PATH': os.path.join('drive','MyDrive','Tensorflow', 'workspace','pre-trained-models1'),\n",
        "    'CHECKPOINT_PATH': os.path.join('drive','MyDrive','Tensorflow', 'workspace','models2',CUSTOM_MODEL_NAME),\n",
        "    'OUTPUT_PATH': os.path.join('drive','MyDrive','Tensorflow', 'workspace','models2',CUSTOM_MODEL_NAME, 'export'),\n",
        "    'TFJS_PATH':os.path.join('drive','MyDrive','Tensorflow', 'workspace','models2',CUSTOM_MODEL_NAME, 'tfjsexport'),\n",
        "    'TFLITE_PATH':os.path.join('drive','MyDrive','Tensorflow', 'workspace','models2',CUSTOM_MODEL_NAME, 'tfliteexport'),\n",
        "    'PROTOC_PATH':os.path.join('drive','MyDrive','Tensorflow','protoc')\n",
        " }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LwhWZMI0pfDC"
      },
      "outputs": [],
      "source": [
        "files = {\n",
        "    'PIPELINE_CONFIG':os.path.join('drive','MyDrive','Tensorflow', 'workspace','models2', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
        "    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME),\n",
        "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HR-TfDGrpfDC"
      },
      "outputs": [],
      "source": [
        "for path in paths.values():\n",
        "    if not os.path.exists(path):\n",
        "        if os.name == 'posix':\n",
        "            !mkdir -p {path}\n",
        "        if os.name == 'nt':\n",
        "            !mkdir {path}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLU-rs_ipfDE"
      },
      "source": [
        "# 1. Download TF Models Pretrained Models from Tensorflow Model Zoo and Install TFOD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVzF6XuTFR5b"
      },
      "outputs": [],
      "source": [
        "# https://www.tensorflow.org/install/source_windows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-Cmz2edpfDE",
        "outputId": "ae77564a-54ea-4a5f-c2ca-4d7598332d76",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9674 sha256=1e4f88023ee0fbd5f52c5fb3a0df49ae36274f2d6a7ba9a194bcbf5570d9c7eb\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/a8/c3/3cf2c14a1837a4e04bd98631724e81f33f462d86a1d895fae0\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ]
        }
      ],
      "source": [
        "pip install wget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YOuLaaSsFR5c"
      },
      "outputs": [],
      "source": [
        "import wget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iA1DIq5OpfDE"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection')):\n",
        "    !git clone https://github.com/tensorflow/models {paths['APIMODEL_PATH']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJjMHbnDs3Tv",
        "outputId": "593fa5df-63e1-4dfa-e7e7-6d493df51896"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "protobuf-compiler is already the newest version (3.6.1.3-2ubuntu5).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-510\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 21 not upgraded.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /content/drive/MyDrive/Tensorflow/models/research\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting avro-python3\n",
            "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting apache-beam\n",
            "  Downloading apache_beam-2.45.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (7.1.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (4.9.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (0.29.33)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (0.5.5)\n",
            "Collecting tf-slim\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m352.1/352.1 KB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (1.15.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (2.0.6)\n",
            "Collecting lvis\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (1.7.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (1.3.5)\n",
            "Collecting tf-models-official>=2.5.1\n",
            "  Downloading tf_models_official-2.11.3-py2.py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m74.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow_io\n",
            "  Downloading tensorflow_io-0.30.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (26.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (2.11.0)\n",
            "Collecting pyparsing==2.4.7\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 KB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sacrebleu<=2.2.0\n",
            "  Downloading sacrebleu-2.2.0-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.6/116.6 KB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (1.21.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.8/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (0.8.10)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (2022.6.2)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.8)\n",
            "Collecting py-cpuinfo>=3.3.0\n",
            "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
            "Collecting pyyaml<6.0,>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp38-cp38-manylinux1_x86_64.whl (662 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m662.4/662.4 KB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-model-optimization>=0.4.1\n",
            "  Downloading tensorflow_model_optimization-0.7.3-py2.py3-none-any.whl (238 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.9/238.9 KB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n",
            "Requirement already satisfied: tensorflow~=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.11.0)\n",
            "Collecting tensorflow-text~=2.11.0\n",
            "  Downloading tensorflow_text-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting immutabledict\n",
            "  Downloading immutabledict-2.2.3-py3-none-any.whl (4.0 kB)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.70.0)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.7.0.68)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.8.2)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 KB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.19.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->object-detection==0.1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->object-detection==0.1) (2022.7.1)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from tf-slim->object-detection==0.1) (1.4.0)\n",
            "Collecting hdfs<3.0.0,>=2.1.0\n",
            "  Downloading hdfs-2.7.0-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n",
            "Collecting fastavro<2,>=0.23.6\n",
            "  Downloading fastavro-1.7.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m88.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow<10.0.0,>=0.15.1 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (9.0.0)\n",
            "Requirement already satisfied: grpcio!=1.48.0,<2,>=1.33.1 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (1.51.1)\n",
            "Collecting pymongo<4.0.0,>=3.8.0\n",
            "  Downloading pymongo-3.13.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (526 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.2/526.2 KB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fasteners<1.0,>=0.3\n",
            "  Downloading fasteners-0.18-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (1.22.2)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n",
            "Collecting zstandard<1,>=0.18.0\n",
            "  Downloading zstandard-0.19.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m80.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httplib2<0.21.0,>=0.8 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (0.17.4)\n",
            "Requirement already satisfied: protobuf<4,>3.12.2 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (3.19.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (4.4.0)\n",
            "Collecting objsize<0.7.0,>=0.6.1\n",
            "  Downloading objsize-0.6.1-py3-none-any.whl (9.3 kB)\n",
            "Collecting orjson<4.0\n",
            "  Downloading orjson-3.8.6-cp38-cp38-manylinux_2_28_x86_64.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.7/140.7 KB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cloudpickle~=2.2.1 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (2.2.1)\n",
            "Collecting dill<0.3.2,>=0.3.1.1\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.0/152.0 KB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (2.25.1)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from lvis->object-detection==0.1) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from lvis->object-detection==0.1) (1.4.4)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.8/dist-packages (from lvis->object-detection==0.1) (4.6.0.66)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.30.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow_io->object-detection==0.1) (0.30.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.11.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.1.1)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.1.0)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=1.19.0 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.16.0)\n",
            "Collecting docopt\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (8.0.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2022.12.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.64.1)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2.10)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (1.14.1)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (2.11.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (15.0.6.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (57.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (23.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (23.1.21)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (2.2.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (2.11.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.8)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.8/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.8/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.8/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.2)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.7.1)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.10.2)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.10.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (7.1.2)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.12.0)\n",
            "Requirement already satisfied: etils[enp,epath]>=0.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.0.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (0.38.4)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.8/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (3.12.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.8/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.58.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (5.3.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (3.4.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.8/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (6.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (3.2.2)\n",
            "Building wheels for collected packages: object-detection, avro-python3, dill, seqeval, docopt\n",
            "  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1696777 sha256=5ffdca0662a3f7c7b2bdf9b155a3d4cfa4ca4f548a78be10db98a3ba2a07cc7e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-19k564bt/wheels/34/a1/85/e3d2b98fd4673d986cd40e22d45b0452d94f591b667d0dd3b3\n",
            "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=44009 sha256=e8290af4e611bb737800bc7aba90951d174995839ba7df2c398fbbdb330f2240\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/73/e9/d273421f5723c4bf544dcf9eb097bda94421ef8d3252699f0a\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78544 sha256=35f0001c4f14247e829ba1f849cbec3cea9eec17f292e20826078371c281502a\n",
            "  Stored in directory: /root/.cache/pip/wheels/07/35/78/e9004fa30578734db7f10e7a211605f3f0778d2bdde38a239d\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16179 sha256=f843240fd4c370ef94e977c46262b8319705facc141691e1dc63557657baeb46\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/5c/ba/05fa33fa5855777b7d686e843ec07452f22a66a138e290e732\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13723 sha256=13325f225df9351589f498d728a1a9d0816cd151c43ae168210103422c4fb58a\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/ea/58/ead137b087d9e326852a851351d1debf4ada529b6ac0ec4e8c\n",
            "Successfully built object-detection avro-python3 dill seqeval docopt\n",
            "Installing collected packages: sentencepiece, py-cpuinfo, docopt, zstandard, tf-slim, tensorflow-model-optimization, tensorflow_io, tensorflow-addons, pyyaml, pyparsing, pymongo, portalocker, orjson, objsize, immutabledict, fasteners, fastavro, dill, colorama, avro-python3, sacrebleu, hdfs, seqeval, lvis, apache-beam, tensorflow-text, tf-models-official, object-detection\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0\n",
            "    Uninstalling PyYAML-6.0:\n",
            "      Successfully uninstalled PyYAML-6.0\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.0.9\n",
            "    Uninstalling pyparsing-3.0.9:\n",
            "      Successfully uninstalled pyparsing-3.0.9\n",
            "  Attempting uninstall: pymongo\n",
            "    Found existing installation: pymongo 4.3.3\n",
            "    Uninstalling pymongo-4.3.3:\n",
            "      Successfully uninstalled pymongo-4.3.3\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.6\n",
            "    Uninstalling dill-0.3.6:\n",
            "      Successfully uninstalled dill-0.3.6\n",
            "Successfully installed apache-beam-2.45.0 avro-python3-1.10.2 colorama-0.4.6 dill-0.3.1.1 docopt-0.6.2 fastavro-1.7.1 fasteners-0.18 hdfs-2.7.0 immutabledict-2.2.3 lvis-0.5.3 object-detection-0.1 objsize-0.6.1 orjson-3.8.6 portalocker-2.7.0 py-cpuinfo-9.0.0 pymongo-3.13.0 pyparsing-2.4.7 pyyaml-5.4.1 sacrebleu-2.2.0 sentencepiece-0.1.97 seqeval-1.2.2 tensorflow-addons-0.19.0 tensorflow-model-optimization-0.7.3 tensorflow-text-2.11.0 tensorflow_io-0.30.0 tf-models-official-2.11.3 tf-slim-1.1.0 zstandard-0.19.0\n"
          ]
        }
      ],
      "source": [
        "# Install Tensorflow Object Detection\n",
        "if os.name=='posix':\n",
        "    !apt-get install protobuf-compiler\n",
        "    !cd drive/MyDrive/Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install .\n",
        "\n",
        "if os.name=='nt':\n",
        "    url=\"https://github.com/protocolbuffers/protobuf/releases/download/v3.15.6/protoc-3.15.6-win64.zip\"\n",
        "    wget.download(url)\n",
        "    !move protoc-3.15.6-win64.zip {paths['PROTOC_PATH']}\n",
        "    !cd {paths['PROTOC_PATH']} && tar -xf protoc-3.15.6-win64.zip\n",
        "    os.environ['PATH'] += os.pathsep + os.path.abspath(os.path.join(paths['PROTOC_PATH'], 'bin'))\n",
        "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && copy object_detection\\\\packages\\\\tf2\\\\setup.py setup.py && python setup.py build && python setup.py install\n",
        "    !cd Tensorflow/models/research/slim && pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdP_8LwBFR5d",
        "outputId": "fff023fe-4046-424c-c90a-24569cfc244e",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-02-14 17:00:51.811432: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-02-14 17:00:53.162797: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-02-14 17:00:53.162897: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-02-14 17:00:53.162917: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Running tests under Python 3.8.10: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "2023-02-14 17:00:58.309057: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "W0214 17:00:58.602028 139713732245312 model_builder.py:1112] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 2.52s\n",
            "I0214 17:00:58.872196 139713732245312 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 2.52s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.64s\n",
            "I0214 17:00:59.513967 139713732245312 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.64s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.3s\n",
            "I0214 17:00:59.816041 139713732245312 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.3s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.26s\n",
            "I0214 17:01:00.080981 139713732245312 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.26s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.95s\n",
            "I0214 17:01:02.035257 139713732245312 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.95s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "I0214 17:01:02.042982 139713732245312 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
            "I0214 17:01:02.067940 139713732245312 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
            "I0214 17:01:02.090198 139713732245312 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
            "I0214 17:01:02.106704 139713732245312 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.26s\n",
            "I0214 17:01:02.367549 139713732245312 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.26s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.09s\n",
            "I0214 17:01:02.460792 139713732245312 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.09s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.15s\n",
            "I0214 17:01:02.606621 139713732245312 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.15s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.16s\n",
            "I0214 17:01:02.764623 139713732245312 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.16s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.14s\n",
            "I0214 17:01:02.908512 139713732245312 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.14s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.04s\n",
            "I0214 17:01:02.953067 139713732245312 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.04s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "I0214 17:01:03.238511 139713732245312 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
            "I0214 17:01:03.238693 139713732245312 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 64\n",
            "I0214 17:01:03.238759 139713732245312 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 3\n",
            "I0214 17:01:03.241998 139713732245312 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0214 17:01:03.279632 139713732245312 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0214 17:01:03.279788 139713732245312 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0214 17:01:03.376972 139713732245312 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0214 17:01:03.377802 139713732245312 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0214 17:01:03.628650 139713732245312 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0214 17:01:03.628831 139713732245312 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0214 17:01:03.878827 139713732245312 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0214 17:01:03.879007 139713732245312 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0214 17:01:04.248799 139713732245312 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0214 17:01:04.248981 139713732245312 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0214 17:01:04.607799 139713732245312 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0214 17:01:04.607977 139713732245312 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0214 17:01:05.098850 139713732245312 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0214 17:01:05.099043 139713732245312 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I0214 17:01:05.210294 139713732245312 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I0214 17:01:05.262661 139713732245312 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0214 17:01:05.337687 139713732245312 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I0214 17:01:05.337867 139713732245312 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 88\n",
            "I0214 17:01:05.337939 139713732245312 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 4\n",
            "I0214 17:01:05.340288 139713732245312 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0214 17:01:05.362386 139713732245312 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0214 17:01:05.362519 139713732245312 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0214 17:01:05.561526 139713732245312 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0214 17:01:05.561712 139713732245312 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0214 17:01:05.918573 139713732245312 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0214 17:01:05.918856 139713732245312 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0214 17:01:06.302551 139713732245312 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0214 17:01:06.302749 139713732245312 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0214 17:01:06.810702 139713732245312 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0214 17:01:06.810908 139713732245312 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0214 17:01:07.344052 139713732245312 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0214 17:01:07.344254 139713732245312 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0214 17:01:07.984826 139713732245312 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0214 17:01:07.985027 139713732245312 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I0214 17:01:08.257137 139713732245312 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I0214 17:01:08.312888 139713732245312 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0214 17:01:08.399359 139713732245312 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
            "I0214 17:01:08.399543 139713732245312 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 112\n",
            "I0214 17:01:08.399636 139713732245312 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 5\n",
            "I0214 17:01:08.401996 139713732245312 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0214 17:01:08.425179 139713732245312 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0214 17:01:08.425302 139713732245312 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0214 17:01:08.586501 139713732245312 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0214 17:01:08.586635 139713732245312 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0214 17:01:08.837912 139713732245312 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0214 17:01:08.838064 139713732245312 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0214 17:01:09.252147 139713732245312 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0214 17:01:09.252334 139713732245312 efficientnet_model.py:143] round_filter input=80 output=88\n",
            "I0214 17:01:09.619142 139713732245312 efficientnet_model.py:143] round_filter input=80 output=88\n",
            "I0214 17:01:09.619312 139713732245312 efficientnet_model.py:143] round_filter input=112 output=120\n",
            "I0214 17:01:09.969192 139713732245312 efficientnet_model.py:143] round_filter input=112 output=120\n",
            "I0214 17:01:09.969350 139713732245312 efficientnet_model.py:143] round_filter input=192 output=208\n",
            "I0214 17:01:10.394555 139713732245312 efficientnet_model.py:143] round_filter input=192 output=208\n",
            "I0214 17:01:10.394709 139713732245312 efficientnet_model.py:143] round_filter input=320 output=352\n",
            "I0214 17:01:10.569347 139713732245312 efficientnet_model.py:143] round_filter input=1280 output=1408\n",
            "I0214 17:01:10.604269 139713732245312 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0214 17:01:10.660350 139713732245312 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
            "I0214 17:01:10.660517 139713732245312 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 160\n",
            "I0214 17:01:10.660597 139713732245312 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 6\n",
            "I0214 17:01:10.662289 139713732245312 efficientnet_model.py:143] round_filter input=32 output=40\n",
            "I0214 17:01:10.682739 139713732245312 efficientnet_model.py:143] round_filter input=32 output=40\n",
            "I0214 17:01:10.682838 139713732245312 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0214 17:01:10.826706 139713732245312 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0214 17:01:10.826849 139713732245312 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0214 17:01:11.102543 139713732245312 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0214 17:01:11.102698 139713732245312 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0214 17:01:11.362165 139713732245312 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0214 17:01:11.362338 139713732245312 efficientnet_model.py:143] round_filter input=80 output=96\n",
            "I0214 17:01:11.815270 139713732245312 efficientnet_model.py:143] round_filter input=80 output=96\n",
            "I0214 17:01:11.815436 139713732245312 efficientnet_model.py:143] round_filter input=112 output=136\n",
            "I0214 17:01:12.268634 139713732245312 efficientnet_model.py:143] round_filter input=112 output=136\n",
            "I0214 17:01:12.268788 139713732245312 efficientnet_model.py:143] round_filter input=192 output=232\n",
            "I0214 17:01:12.785867 139713732245312 efficientnet_model.py:143] round_filter input=192 output=232\n",
            "I0214 17:01:12.786023 139713732245312 efficientnet_model.py:143] round_filter input=320 output=384\n",
            "I0214 17:01:12.981958 139713732245312 efficientnet_model.py:143] round_filter input=1280 output=1536\n",
            "I0214 17:01:13.022744 139713732245312 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0214 17:01:13.087040 139713732245312 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
            "I0214 17:01:13.087198 139713732245312 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 224\n",
            "I0214 17:01:13.087278 139713732245312 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 7\n",
            "I0214 17:01:13.088982 139713732245312 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0214 17:01:13.108834 139713732245312 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0214 17:01:13.108938 139713732245312 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0214 17:01:13.257451 139713732245312 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0214 17:01:13.257636 139713732245312 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0214 17:01:13.597888 139713732245312 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0214 17:01:13.598046 139713732245312 efficientnet_model.py:143] round_filter input=40 output=56\n",
            "I0214 17:01:13.943327 139713732245312 efficientnet_model.py:143] round_filter input=40 output=56\n",
            "I0214 17:01:13.943522 139713732245312 efficientnet_model.py:143] round_filter input=80 output=112\n",
            "I0214 17:01:14.430211 139713732245312 efficientnet_model.py:143] round_filter input=80 output=112\n",
            "I0214 17:01:14.430374 139713732245312 efficientnet_model.py:143] round_filter input=112 output=160\n",
            "I0214 17:01:14.973653 139713732245312 efficientnet_model.py:143] round_filter input=112 output=160\n",
            "I0214 17:01:14.973818 139713732245312 efficientnet_model.py:143] round_filter input=192 output=272\n",
            "I0214 17:01:15.888626 139713732245312 efficientnet_model.py:143] round_filter input=192 output=272\n",
            "I0214 17:01:15.888849 139713732245312 efficientnet_model.py:143] round_filter input=320 output=448\n",
            "I0214 17:01:16.071997 139713732245312 efficientnet_model.py:143] round_filter input=1280 output=1792\n",
            "I0214 17:01:16.107701 139713732245312 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0214 17:01:16.179092 139713732245312 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
            "I0214 17:01:16.179258 139713732245312 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 288\n",
            "I0214 17:01:16.179340 139713732245312 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 7\n",
            "I0214 17:01:16.180886 139713732245312 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0214 17:01:16.197823 139713732245312 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0214 17:01:16.197924 139713732245312 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0214 17:01:16.402571 139713732245312 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0214 17:01:16.402725 139713732245312 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0214 17:01:16.855793 139713732245312 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0214 17:01:16.855962 139713732245312 efficientnet_model.py:143] round_filter input=40 output=64\n",
            "I0214 17:01:17.284075 139713732245312 efficientnet_model.py:143] round_filter input=40 output=64\n",
            "I0214 17:01:17.284246 139713732245312 efficientnet_model.py:143] round_filter input=80 output=128\n",
            "I0214 17:01:17.884556 139713732245312 efficientnet_model.py:143] round_filter input=80 output=128\n",
            "I0214 17:01:17.884712 139713732245312 efficientnet_model.py:143] round_filter input=112 output=176\n",
            "I0214 17:01:18.467992 139713732245312 efficientnet_model.py:143] round_filter input=112 output=176\n",
            "I0214 17:01:18.468150 139713732245312 efficientnet_model.py:143] round_filter input=192 output=304\n",
            "I0214 17:01:19.494056 139713732245312 efficientnet_model.py:143] round_filter input=192 output=304\n",
            "I0214 17:01:19.494357 139713732245312 efficientnet_model.py:143] round_filter input=320 output=512\n",
            "I0214 17:01:19.857710 139713732245312 efficientnet_model.py:143] round_filter input=1280 output=2048\n",
            "I0214 17:01:19.911888 139713732245312 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0214 17:01:20.043785 139713732245312 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
            "I0214 17:01:20.043960 139713732245312 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 384\n",
            "I0214 17:01:20.044045 139713732245312 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 8\n",
            "I0214 17:01:20.047171 139713732245312 efficientnet_model.py:143] round_filter input=32 output=56\n",
            "I0214 17:01:20.072535 139713732245312 efficientnet_model.py:143] round_filter input=32 output=56\n",
            "I0214 17:01:20.072655 139713732245312 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0214 17:01:20.347625 139713732245312 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0214 17:01:20.347806 139713732245312 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0214 17:01:21.040242 139713732245312 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0214 17:01:21.040419 139713732245312 efficientnet_model.py:143] round_filter input=40 output=72\n",
            "I0214 17:01:21.724376 139713732245312 efficientnet_model.py:143] round_filter input=40 output=72\n",
            "I0214 17:01:21.724596 139713732245312 efficientnet_model.py:143] round_filter input=80 output=144\n",
            "I0214 17:01:22.762176 139713732245312 efficientnet_model.py:143] round_filter input=80 output=144\n",
            "I0214 17:01:22.762367 139713732245312 efficientnet_model.py:143] round_filter input=112 output=200\n",
            "I0214 17:01:24.188677 139713732245312 efficientnet_model.py:143] round_filter input=112 output=200\n",
            "I0214 17:01:24.188868 139713732245312 efficientnet_model.py:143] round_filter input=192 output=344\n",
            "I0214 17:01:25.291948 139713732245312 efficientnet_model.py:143] round_filter input=192 output=344\n",
            "I0214 17:01:25.292110 139713732245312 efficientnet_model.py:143] round_filter input=320 output=576\n",
            "I0214 17:01:25.548990 139713732245312 efficientnet_model.py:143] round_filter input=1280 output=2304\n",
            "I0214 17:01:25.584880 139713732245312 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0214 17:01:25.676234 139713732245312 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
            "I0214 17:01:25.676419 139713732245312 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 384\n",
            "I0214 17:01:25.676522 139713732245312 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 8\n",
            "I0214 17:01:25.679195 139713732245312 efficientnet_model.py:143] round_filter input=32 output=64\n",
            "I0214 17:01:25.702906 139713732245312 efficientnet_model.py:143] round_filter input=32 output=64\n",
            "I0214 17:01:25.703030 139713732245312 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0214 17:01:25.988428 139713732245312 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0214 17:01:25.988595 139713732245312 efficientnet_model.py:143] round_filter input=24 output=48\n",
            "I0214 17:01:26.571193 139713732245312 efficientnet_model.py:143] round_filter input=24 output=48\n",
            "I0214 17:01:26.571362 139713732245312 efficientnet_model.py:143] round_filter input=40 output=80\n",
            "I0214 17:01:27.160882 139713732245312 efficientnet_model.py:143] round_filter input=40 output=80\n",
            "I0214 17:01:27.161038 139713732245312 efficientnet_model.py:143] round_filter input=80 output=160\n",
            "I0214 17:01:27.980795 139713732245312 efficientnet_model.py:143] round_filter input=80 output=160\n",
            "I0214 17:01:27.980951 139713732245312 efficientnet_model.py:143] round_filter input=112 output=224\n",
            "I0214 17:01:28.837668 139713732245312 efficientnet_model.py:143] round_filter input=112 output=224\n",
            "I0214 17:01:28.837825 139713732245312 efficientnet_model.py:143] round_filter input=192 output=384\n",
            "I0214 17:01:29.955841 139713732245312 efficientnet_model.py:143] round_filter input=192 output=384\n",
            "I0214 17:01:29.956005 139713732245312 efficientnet_model.py:143] round_filter input=320 output=640\n",
            "I0214 17:01:30.304821 139713732245312 efficientnet_model.py:143] round_filter input=1280 output=2560\n",
            "I0214 17:01:30.340759 139713732245312 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 27.74s\n",
            "I0214 17:01:30.693638 139713732245312 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 27.74s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "I0214 17:01:30.727480 139713732245312 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "I0214 17:01:30.730063 139713732245312 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "I0214 17:01:30.730692 139713732245312 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "I0214 17:01:30.732842 139713732245312 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTF2Test.test_session\n",
            "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "I0214 17:01:30.734628 139713732245312 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "I0214 17:01:30.735103 139713732245312 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "I0214 17:01:30.736440 139713732245312 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 24 tests in 34.381s\n",
            "\n",
            "OK (skipped=1)\n"
          ]
        }
      ],
      "source": [
        "VERIFICATION_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')\n",
        "# Verify Installation\n",
        "!python {VERIFICATION_SCRIPT}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJ_DS3q9FR5d",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "!pip install gin-config==0.1.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6acBI-L7FR5d"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow-addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4K5f67UFR5e"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nrVYRvquFR5e"
      },
      "outputs": [],
      "source": [
        "!pip uninstall protobuf matplotlib -y\n",
        "!pip install protobuf matplotlib==3.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vtCnjiO9FR5e"
      },
      "outputs": [],
      "source": [
        "!pip install object_detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQU8SoFuFR5e"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Xnj6UfBFR5e"
      },
      "outputs": [],
      "source": [
        "import object_detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGMpuMDHFR5e",
        "outputId": "7ae91f65-baeb-4d65-c7b5-47400e770e1a",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Package                       Version\n",
            "----------------------------- ----------------------\n",
            "absl-py                       1.4.0\n",
            "aeppl                         0.0.33\n",
            "aesara                        2.7.9\n",
            "aiohttp                       3.8.3\n",
            "aiosignal                     1.3.1\n",
            "alabaster                     0.7.13\n",
            "albumentations                1.2.1\n",
            "altair                        4.2.2\n",
            "apache-beam                   2.44.0\n",
            "appdirs                       1.4.4\n",
            "arviz                         0.12.1\n",
            "astor                         0.8.1\n",
            "astropy                       4.3.1\n",
            "astunparse                    1.6.3\n",
            "async-timeout                 4.0.2\n",
            "atari-py                      0.2.9\n",
            "atomicwrites                  1.4.1\n",
            "attrs                         22.2.0\n",
            "audioread                     3.0.0\n",
            "autograd                      1.5\n",
            "avro-python3                  1.10.2\n",
            "Babel                         2.11.0\n",
            "backcall                      0.2.0\n",
            "beautifulsoup4                4.6.3\n",
            "bleach                        6.0.0\n",
            "blis                          0.7.9\n",
            "bokeh                         2.3.3\n",
            "branca                        0.6.0\n",
            "bs4                           0.0.1\n",
            "CacheControl                  0.12.11\n",
            "cachetools                    5.3.0\n",
            "catalogue                     2.0.8\n",
            "certifi                       2022.12.7\n",
            "cffi                          1.15.1\n",
            "cftime                        1.6.2\n",
            "chardet                       4.0.0\n",
            "charset-normalizer            2.1.1\n",
            "click                         7.1.2\n",
            "clikit                        0.6.2\n",
            "cloudpickle                   2.2.1\n",
            "cmake                         3.22.6\n",
            "cmdstanpy                     1.1.0\n",
            "colorama                      0.4.6\n",
            "colorcet                      3.0.1\n",
            "colorlover                    0.3.0\n",
            "community                     1.0.0b1\n",
            "confection                    0.0.4\n",
            "cons                          0.4.5\n",
            "contextlib2                   0.5.5\n",
            "convertdate                   2.4.0\n",
            "crashtest                     0.3.1\n",
            "crcmod                        1.7\n",
            "cufflinks                     0.17.3\n",
            "cupy-cuda11x                  11.0.0\n",
            "cvxopt                        1.3.0\n",
            "cvxpy                         1.2.3\n",
            "cycler                        0.11.0\n",
            "cymem                         2.0.7\n",
            "Cython                        0.29.33\n",
            "daft                          0.0.4\n",
            "dask                          2022.2.1\n",
            "datascience                   0.17.5\n",
            "db-dtypes                     1.0.5\n",
            "dbus-python                   1.2.16\n",
            "debugpy                       1.0.0\n",
            "decorator                     4.4.2\n",
            "defusedxml                    0.7.1\n",
            "descartes                     1.1.0\n",
            "dill                          0.3.1.1\n",
            "distributed                   2022.2.1\n",
            "dlib                          19.24.0\n",
            "dm-tree                       0.1.8\n",
            "dnspython                     2.3.0\n",
            "docopt                        0.6.2\n",
            "docutils                      0.16\n",
            "dopamine-rl                   1.0.5\n",
            "earthengine-api               0.1.340\n",
            "easydict                      1.10\n",
            "ecos                          2.0.12\n",
            "editdistance                  0.5.3\n",
            "en-core-web-sm                3.4.1\n",
            "entrypoints                   0.4\n",
            "ephem                         4.1.4\n",
            "et-xmlfile                    1.1.0\n",
            "etils                         1.0.0\n",
            "etuples                       0.3.8\n",
            "fa2                           0.3.5\n",
            "fastai                        2.7.10\n",
            "fastavro                      1.7.1\n",
            "fastcore                      1.5.28\n",
            "fastdownload                  0.0.7\n",
            "fastdtw                       0.3.4\n",
            "fasteners                     0.18\n",
            "fastjsonschema                2.16.2\n",
            "fastprogress                  1.0.3\n",
            "fastrlock                     0.8.1\n",
            "feather-format                0.4.1\n",
            "filelock                      3.9.0\n",
            "firebase-admin                5.3.0\n",
            "fix-yahoo-finance             0.0.22\n",
            "Flask                         1.1.4\n",
            "flatbuffers                   23.1.21\n",
            "folium                        0.12.1.post1\n",
            "frozenlist                    1.3.3\n",
            "fsspec                        2023.1.0\n",
            "future                        0.16.0\n",
            "gast                          0.4.0\n",
            "GDAL                          3.3.2\n",
            "gdown                         4.4.0\n",
            "gensim                        3.6.0\n",
            "geographiclib                 1.52\n",
            "geopy                         1.17.0\n",
            "gin-config                    0.5.0\n",
            "glob2                         0.7\n",
            "google                        2.0.3\n",
            "google-api-core               2.11.0\n",
            "google-api-python-client      2.70.0\n",
            "google-auth                   2.16.0\n",
            "google-auth-httplib2          0.1.0\n",
            "google-auth-oauthlib          0.4.6\n",
            "google-cloud-bigquery         3.4.2\n",
            "google-cloud-bigquery-storage 2.18.1\n",
            "google-cloud-core             2.3.2\n",
            "google-cloud-datastore        2.11.1\n",
            "google-cloud-firestore        2.7.3\n",
            "google-cloud-language         2.6.1\n",
            "google-cloud-storage          2.7.0\n",
            "google-cloud-translate        3.8.4\n",
            "google-colab                  1.0.0\n",
            "google-crc32c                 1.5.0\n",
            "google-pasta                  0.2.0\n",
            "google-resumable-media        2.4.1\n",
            "googleapis-common-protos      1.58.0\n",
            "googledrivedownloader         0.4\n",
            "graphviz                      0.10.1\n",
            "greenlet                      2.0.2\n",
            "grpcio                        1.51.1\n",
            "grpcio-status                 1.48.2\n",
            "gspread                       3.4.2\n",
            "gspread-dataframe             3.0.8\n",
            "gym                           0.25.2\n",
            "gym-notices                   0.0.8\n",
            "h5py                          3.1.0\n",
            "hdfs                          2.7.0\n",
            "HeapDict                      1.0.1\n",
            "hijri-converter               2.2.4\n",
            "holidays                      0.19\n",
            "holoviews                     1.14.9\n",
            "html5lib                      1.0.1\n",
            "httpimport                    0.5.18\n",
            "httplib2                      0.17.4\n",
            "httpstan                      4.6.1\n",
            "humanize                      0.5.1\n",
            "hyperopt                      0.1.2\n",
            "idna                          2.10\n",
            "imageio                       2.9.0\n",
            "imagesize                     1.4.1\n",
            "imbalanced-learn              0.8.1\n",
            "imblearn                      0.0\n",
            "imgaug                        0.4.0\n",
            "immutabledict                 2.2.3\n",
            "importlib-metadata            6.0.0\n",
            "importlib-resources           5.10.2\n",
            "imutils                       0.5.4\n",
            "inflect                       2.1.0\n",
            "intel-openmp                  2023.0.0\n",
            "intervaltree                  2.1.0\n",
            "ipykernel                     5.3.4\n",
            "ipython                       7.9.0\n",
            "ipython-genutils              0.2.0\n",
            "ipython-sql                   0.3.9\n",
            "ipywidgets                    7.7.1\n",
            "itsdangerous                  1.1.0\n",
            "jax                           0.3.25\n",
            "jaxlib                        0.3.25+cuda11.cudnn805\n",
            "jieba                         0.42.1\n",
            "Jinja2                        2.11.3\n",
            "joblib                        1.2.0\n",
            "jpeg4py                       0.1.4\n",
            "jsonschema                    4.3.3\n",
            "jupyter-client                6.1.12\n",
            "jupyter-console               6.1.0\n",
            "jupyter_core                  5.2.0\n",
            "jupyterlab-widgets            3.0.5\n",
            "kaggle                        1.5.12\n",
            "kapre                         0.3.7\n",
            "keras                         2.11.0\n",
            "keras-vis                     0.4.1\n",
            "kiwisolver                    1.4.4\n",
            "korean-lunar-calendar         0.3.1\n",
            "langcodes                     3.3.0\n",
            "libclang                      15.0.6.1\n",
            "librosa                       0.8.1\n",
            "lightgbm                      2.2.3\n",
            "llvmlite                      0.39.1\n",
            "lmdb                          0.99\n",
            "locket                        1.0.0\n",
            "logical-unification           0.4.5\n",
            "LunarCalendar                 0.0.9\n",
            "lvis                          0.5.3\n",
            "lxml                          4.9.2\n",
            "Markdown                      3.4.1\n",
            "MarkupSafe                    2.0.1\n",
            "marshmallow                   3.19.0\n",
            "matplotlib                    3.2.2\n",
            "matplotlib-venn               0.11.7\n",
            "miniKanren                    1.0.3\n",
            "missingno                     0.5.1\n",
            "mistune                       0.8.4\n",
            "mizani                        0.7.3\n",
            "mkl                           2019.0\n",
            "mlxtend                       0.14.0\n",
            "more-itertools                9.0.0\n",
            "moviepy                       0.2.3.5\n",
            "mpmath                        1.2.1\n",
            "msgpack                       1.0.4\n",
            "multidict                     6.0.4\n",
            "multipledispatch              0.6.0\n",
            "multitasking                  0.0.11\n",
            "murmurhash                    1.0.9\n",
            "music21                       5.5.0\n",
            "natsort                       5.5.0\n",
            "nbconvert                     5.6.1\n",
            "nbformat                      5.7.3\n",
            "netCDF4                       1.6.2\n",
            "networkx                      3.0\n",
            "nibabel                       3.0.2\n",
            "nltk                          3.7\n",
            "notebook                      5.7.16\n",
            "numba                         0.56.4\n",
            "numexpr                       2.8.4\n",
            "numpy                         1.21.6\n",
            "oauth2client                  4.1.3\n",
            "oauthlib                      3.2.2\n",
            "object-detection              0.1\n",
            "objsize                       0.6.1\n",
            "okgrade                       0.4.3\n",
            "opencv-contrib-python         4.6.0.66\n",
            "opencv-python                 4.6.0.66\n",
            "opencv-python-headless        4.7.0.68\n",
            "openpyxl                      3.0.10\n",
            "opt-einsum                    3.3.0\n",
            "orjson                        3.8.6\n",
            "osqp                          0.6.2.post0\n",
            "packaging                     23.0\n",
            "palettable                    3.3.0\n",
            "pandas                        1.3.5\n",
            "pandas-datareader             0.9.0\n",
            "pandas-gbq                    0.17.9\n",
            "pandas-profiling              1.4.1\n",
            "pandocfilters                 1.5.0\n",
            "panel                         0.12.1\n",
            "param                         1.12.3\n",
            "parso                         0.8.3\n",
            "partd                         1.3.0\n",
            "pastel                        0.2.1\n",
            "pathlib                       1.0.1\n",
            "pathy                         0.10.1\n",
            "patsy                         0.5.3\n",
            "pep517                        0.13.0\n",
            "pexpect                       4.8.0\n",
            "pickleshare                   0.7.5\n",
            "Pillow                        7.1.2\n",
            "pip                           22.0.4\n",
            "pip-tools                     6.6.2\n",
            "platformdirs                  3.0.0\n",
            "plotly                        5.5.0\n",
            "plotnine                      0.8.0\n",
            "pluggy                        0.7.1\n",
            "pooch                         1.6.0\n",
            "portalocker                   2.7.0\n",
            "portpicker                    1.3.9\n",
            "prefetch-generator            1.0.3\n",
            "preshed                       3.0.8\n",
            "prettytable                   3.6.0\n",
            "progressbar2                  3.38.0\n",
            "prometheus-client             0.16.0\n",
            "promise                       2.3\n",
            "prompt-toolkit                2.0.10\n",
            "prophet                       1.1.2\n",
            "proto-plus                    1.22.2\n",
            "protobuf                      3.19.6\n",
            "psutil                        5.4.8\n",
            "psycopg2                      2.9.5\n",
            "ptyprocess                    0.7.0\n",
            "py                            1.11.0\n",
            "py-cpuinfo                    9.0.0\n",
            "pyarrow                       9.0.0\n",
            "pyasn1                        0.4.8\n",
            "pyasn1-modules                0.2.8\n",
            "pycocotools                   2.0.6\n",
            "pycparser                     2.21\n",
            "pyct                          0.5.0\n",
            "pydantic                      1.10.4\n",
            "pydata-google-auth            1.7.0\n",
            "pydot                         1.3.0\n",
            "pydot-ng                      2.0.0\n",
            "pydotplus                     2.0.2\n",
            "PyDrive                       1.3.1\n",
            "pyemd                         0.5.1\n",
            "pyerfa                        2.0.0.1\n",
            "Pygments                      2.6.1\n",
            "PyGObject                     3.36.0\n",
            "pylev                         1.4.0\n",
            "pymc                          4.1.4\n",
            "PyMeeus                       0.5.12\n",
            "pymongo                       3.13.0\n",
            "pymystem3                     0.2.0\n",
            "PyOpenGL                      3.1.6\n",
            "pyparsing                     2.4.7\n",
            "pyrsistent                    0.19.3\n",
            "pysimdjson                    3.2.0\n",
            "PySocks                       1.7.1\n",
            "pystan                        3.3.0\n",
            "pytest                        3.6.4\n",
            "python-apt                    2.0.1\n",
            "python-dateutil               2.8.2\n",
            "python-louvain                0.16\n",
            "python-slugify                8.0.0\n",
            "python-utils                  3.5.0\n",
            "pytz                          2022.7.1\n",
            "pyviz-comms                   2.2.1\n",
            "PyWavelets                    1.4.1\n",
            "PyYAML                        5.4.1\n",
            "pyzmq                         23.2.1\n",
            "qdldl                         0.1.5.post3\n",
            "qudida                        0.0.4\n",
            "regex                         2022.6.2\n",
            "requests                      2.25.1\n",
            "requests-oauthlib             1.3.1\n",
            "requests-unixsocket           0.2.0\n",
            "resampy                       0.4.2\n",
            "rpy2                          3.5.5\n",
            "rsa                           4.9\n",
            "sacrebleu                     2.2.0\n",
            "scikit-image                  0.18.3\n",
            "scikit-learn                  1.0.2\n",
            "scipy                         1.7.3\n",
            "screen-resolution-extra       0.0.0\n",
            "scs                           3.2.2\n",
            "seaborn                       0.11.2\n",
            "Send2Trash                    1.8.0\n",
            "sentencepiece                 0.1.97\n",
            "seqeval                       1.2.2\n",
            "setuptools                    57.4.0\n",
            "shapely                       2.0.1\n",
            "six                           1.15.0\n",
            "sklearn-pandas                1.8.0\n",
            "smart-open                    6.3.0\n",
            "snowballstemmer               2.2.0\n",
            "sortedcontainers              2.4.0\n",
            "soundfile                     0.11.0\n",
            "spacy                         3.4.4\n",
            "spacy-legacy                  3.0.12\n",
            "spacy-loggers                 1.0.4\n",
            "Sphinx                        3.5.4\n",
            "sphinxcontrib-applehelp       1.0.4\n",
            "sphinxcontrib-devhelp         1.0.2\n",
            "sphinxcontrib-htmlhelp        2.0.1\n",
            "sphinxcontrib-jsmath          1.0.1\n",
            "sphinxcontrib-qthelp          1.0.3\n",
            "sphinxcontrib-serializinghtml 1.1.5\n",
            "SQLAlchemy                    1.4.46\n",
            "sqlparse                      0.4.3\n",
            "srsly                         2.4.5\n",
            "statsmodels                   0.12.2\n",
            "sympy                         1.7.1\n",
            "tables                        3.7.0\n",
            "tabulate                      0.8.10\n",
            "tblib                         1.7.0\n",
            "tenacity                      8.2.0\n",
            "tensorboard                   2.11.2\n",
            "tensorboard-data-server       0.6.1\n",
            "tensorboard-plugin-wit        1.8.1\n",
            "tensorflow                    2.11.0\n",
            "tensorflow-addons             0.19.0\n",
            "tensorflow-datasets           4.8.2\n",
            "tensorflow-estimator          2.11.0\n",
            "tensorflow-gcs-config         2.11.0\n",
            "tensorflow-hub                0.12.0\n",
            "tensorflow-io                 0.30.0\n",
            "tensorflow-io-gcs-filesystem  0.30.0\n",
            "tensorflow-metadata           1.12.0\n",
            "tensorflow-model-optimization 0.7.3\n",
            "tensorflow-probability        0.19.0\n",
            "tensorflow-text               2.11.0\n",
            "termcolor                     2.2.0\n",
            "terminado                     0.13.3\n",
            "testpath                      0.6.0\n",
            "text-unidecode                1.3\n",
            "textblob                      0.15.3\n",
            "tf-models-official            2.11.3\n",
            "tf-slim                       1.1.0\n",
            "thinc                         8.1.7\n",
            "threadpoolctl                 3.1.0\n",
            "tifffile                      2023.2.3\n",
            "toml                          0.10.2\n",
            "tomli                         2.0.1\n",
            "toolz                         0.12.0\n",
            "torch                         1.13.1+cu116\n",
            "torchaudio                    0.13.1+cu116\n",
            "torchsummary                  1.5.1\n",
            "torchtext                     0.14.1\n",
            "torchvision                   0.14.1+cu116\n",
            "tornado                       6.0.4\n",
            "tqdm                          4.64.1\n",
            "traitlets                     5.7.1\n",
            "tweepy                        3.10.0\n",
            "typeguard                     2.7.1\n",
            "typer                         0.7.0\n",
            "typing_extensions             4.4.0\n",
            "tzlocal                       1.5.1\n",
            "uritemplate                   4.1.1\n",
            "urllib3                       1.24.3\n",
            "vega-datasets                 0.9.0\n",
            "wasabi                        0.10.1\n",
            "wcwidth                       0.2.6\n",
            "webargs                       8.2.0\n",
            "webencodings                  0.5.1\n",
            "Werkzeug                      1.0.1\n",
            "wget                          3.2\n",
            "wheel                         0.38.4\n",
            "widgetsnbextension            3.6.1\n",
            "wordcloud                     1.8.2.2\n",
            "wrapt                         1.14.1\n",
            "xarray                        2022.12.0\n",
            "xarray-einstats               0.5.1\n",
            "xgboost                       0.90\n",
            "xkit                          0.0.0\n",
            "xlrd                          1.2.0\n",
            "xlwt                          1.3.0\n",
            "yarl                          1.8.2\n",
            "yellowbrick                   1.5\n",
            "zict                          2.2.0\n",
            "zipp                          3.12.1\n",
            "zstandard                     0.19.0\n"
          ]
        }
      ],
      "source": [
        "!pip list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csofht2npfDE",
        "outputId": "812beb80-5bd7-40f9-be46-b1f2bef68106"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-14 17:01:54--  http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet152_v1_640x640_coco17_tpu-8.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 74.125.68.128, 2404:6800:4003:c02::80\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|74.125.68.128|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 470656289 (449M) [application/x-tar]\n",
            "Saving to: ‘faster_rcnn_resnet152_v1_640x640_coco17_tpu-8.tar.gz’\n",
            "\n",
            "faster_rcnn_resnet1 100%[===================>] 448.85M  50.8MB/s    in 9.7s    \n",
            "\n",
            "2023-02-14 17:02:05 (46.5 MB/s) - ‘faster_rcnn_resnet152_v1_640x640_coco17_tpu-8.tar.gz’ saved [470656289/470656289]\n",
            "\n",
            "faster_rcnn_resnet152_v1_640x640_coco17_tpu-8/\n",
            "faster_rcnn_resnet152_v1_640x640_coco17_tpu-8/checkpoint/\n",
            "faster_rcnn_resnet152_v1_640x640_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
            "faster_rcnn_resnet152_v1_640x640_coco17_tpu-8/checkpoint/checkpoint\n",
            "faster_rcnn_resnet152_v1_640x640_coco17_tpu-8/checkpoint/ckpt-0.index\n",
            "faster_rcnn_resnet152_v1_640x640_coco17_tpu-8/pipeline.config\n",
            "faster_rcnn_resnet152_v1_640x640_coco17_tpu-8/saved_model/\n",
            "faster_rcnn_resnet152_v1_640x640_coco17_tpu-8/saved_model/saved_model.pb\n",
            "faster_rcnn_resnet152_v1_640x640_coco17_tpu-8/saved_model/variables/\n",
            "faster_rcnn_resnet152_v1_640x640_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
            "faster_rcnn_resnet152_v1_640x640_coco17_tpu-8/saved_model/variables/variables.index\n"
          ]
        }
      ],
      "source": [
        "if os.name =='posix':\n",
        "    !wget {PRETRAINED_MODEL_URL}\n",
        "    !mv {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
        "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}\n",
        "if os.name == 'nt':\n",
        "    wget.download(PRETRAINED_MODEL_URL)\n",
        "    !move {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
        "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5KJTnkfpfDC"
      },
      "source": [
        "# 2. Create Label Map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1BVDWo7pfDC"
      },
      "outputs": [],
      "source": [
        "labels = [{'name':'Battery', 'id':1}, {'name':'BoltWasher', 'id':2},{'name':'ClampPart', 'id':3},  {'name':'Cutter', 'id':4}, {'name':'PlasticPart', 'id':5}, {'name':'Bolt', 'id':6}, {'name':'LuggageTag', 'id':7}, {'name':'Nail', 'id':8}, {'name':'Pliers', 'id':9}, {'name':'Label', 'id':10}, {'name':'Washer', 'id':11}, {'name':'Wrench', 'id':12}, {'name':'FuelCap', 'id':13}, {'name':'Nut', 'id':14}, {'name':'MetalSheet', 'id':15}, {'name':'Hose', 'id':16}, {'name':'AdjustableClamp', 'id':17}, {'name':'AdjustableWrench', 'id':18}, {'name':'BoltNutSet', 'id':19}, {'name':'Hammer', 'id':20}, {'name':'LuggagePart', 'id':21}, {'name':'MetalPart', 'id':22}, {'name':'PaintChip', 'id':23}, {'name':'Pen', 'id':24}, {'name':'Rock', 'id':25}, {'name':'Screw', 'id':26}, {'name':'Screwdriver', 'id':27},{'name':'SodaCan', 'id':28}, {'name':'Wood', 'id':29}, {'name':'Wire', 'id':30}, {'name':'Tape', 'id':31}]\n",
        "with open(files['LABELMAP'], 'w') as f:\n",
        "    for label in labels:\n",
        "        f.write('item { \\n')\n",
        "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
        "        f.write('\\tid:{}\\n'.format(label['id']))\n",
        "        f.write('}\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C88zyVELpfDC"
      },
      "source": [
        "# 3. Create TF records"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWpb_BVUpfDD"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(files['TF_RECORD_SCRIPT']):\n",
        "    !git clone https://github.com/nicknochnack/GenerateTFRecord {paths['SCRIPTS_PATH']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eM-HoLBsFR5f"
      },
      "outputs": [],
      "source": [
        "x=os.path.join(paths['TRAIN_PATH'], 'train1')\n",
        "y=os.path.join(paths['IMAGE_PATH'], 'test','test1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPFToGZqpfDD",
        "outputId": "0ebb456f-aadc-4a1f-96e6-fbfec1923e1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully created the TFRecord file: Tensorflow\\workspace\\annotations\\train.record\n"
          ]
        }
      ],
      "source": [
        "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'train')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'train.record')}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4rxX7MzBFR5g",
        "outputId": "9786938c-1739-4306-9703-ba34cf358645"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully created the TFRecord file: Tensorflow\\workspace\\annotations\\test.record\n"
          ]
        }
      ],
      "source": [
        "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'test')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'test.record')}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qT4QU7pLpfDE"
      },
      "source": [
        "# 4. Copy Model Config to Training Folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cOjuTFbwpfDF",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "if os.name =='posix':\n",
        "    !cp {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}\n",
        "if os.name == 'nt':\n",
        "    !copy {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ga8gpNslpfDF"
      },
      "source": [
        "# 5. Update Config For Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9hRrO_ppfDF"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.protos import pipeline_pb2\n",
        "from google.protobuf import text_format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2A0mn4ipfDF"
      },
      "outputs": [],
      "source": [
        "config = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQA13-afpfDF",
        "outputId": "c6081467-10b6-420a-c516-e800c5a52bef"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'model': faster_rcnn {\n",
              "   num_classes: 90\n",
              "   image_resizer {\n",
              "     keep_aspect_ratio_resizer {\n",
              "       min_dimension: 640\n",
              "       max_dimension: 640\n",
              "       pad_to_max_dimension: true\n",
              "     }\n",
              "   }\n",
              "   feature_extractor {\n",
              "     type: \"faster_rcnn_resnet152_keras\"\n",
              "     batch_norm_trainable: true\n",
              "   }\n",
              "   first_stage_anchor_generator {\n",
              "     grid_anchor_generator {\n",
              "       height_stride: 16\n",
              "       width_stride: 16\n",
              "       scales: 0.25\n",
              "       scales: 0.5\n",
              "       scales: 1.0\n",
              "       scales: 2.0\n",
              "       aspect_ratios: 0.5\n",
              "       aspect_ratios: 1.0\n",
              "       aspect_ratios: 2.0\n",
              "     }\n",
              "   }\n",
              "   first_stage_box_predictor_conv_hyperparams {\n",
              "     op: CONV\n",
              "     regularizer {\n",
              "       l2_regularizer {\n",
              "         weight: 0.0\n",
              "       }\n",
              "     }\n",
              "     initializer {\n",
              "       truncated_normal_initializer {\n",
              "         stddev: 0.009999999776482582\n",
              "       }\n",
              "     }\n",
              "   }\n",
              "   first_stage_nms_score_threshold: 0.0\n",
              "   first_stage_nms_iou_threshold: 0.699999988079071\n",
              "   first_stage_max_proposals: 300\n",
              "   first_stage_localization_loss_weight: 2.0\n",
              "   first_stage_objectness_loss_weight: 1.0\n",
              "   initial_crop_size: 14\n",
              "   maxpool_kernel_size: 2\n",
              "   maxpool_stride: 2\n",
              "   second_stage_box_predictor {\n",
              "     mask_rcnn_box_predictor {\n",
              "       fc_hyperparams {\n",
              "         op: FC\n",
              "         regularizer {\n",
              "           l2_regularizer {\n",
              "             weight: 0.0\n",
              "           }\n",
              "         }\n",
              "         initializer {\n",
              "           variance_scaling_initializer {\n",
              "             factor: 1.0\n",
              "             uniform: true\n",
              "             mode: FAN_AVG\n",
              "           }\n",
              "         }\n",
              "       }\n",
              "       use_dropout: false\n",
              "       dropout_keep_probability: 1.0\n",
              "       share_box_across_classes: true\n",
              "     }\n",
              "   }\n",
              "   second_stage_post_processing {\n",
              "     batch_non_max_suppression {\n",
              "       score_threshold: 0.0\n",
              "       iou_threshold: 0.6000000238418579\n",
              "       max_detections_per_class: 100\n",
              "       max_total_detections: 300\n",
              "     }\n",
              "     score_converter: SOFTMAX\n",
              "   }\n",
              "   second_stage_localization_loss_weight: 2.0\n",
              "   second_stage_classification_loss_weight: 1.0\n",
              "   use_matmul_crop_and_resize: true\n",
              "   clip_anchors_to_image: true\n",
              "   use_matmul_gather_in_matcher: true\n",
              "   use_static_balanced_label_sampler: true\n",
              "   use_static_shapes: true\n",
              " }, 'train_config': batch_size: 64\n",
              " data_augmentation_options {\n",
              "   random_horizontal_flip {\n",
              "   }\n",
              " }\n",
              " sync_replicas: true\n",
              " optimizer {\n",
              "   momentum_optimizer {\n",
              "     learning_rate {\n",
              "       cosine_decay_learning_rate {\n",
              "         learning_rate_base: 0.03999999910593033\n",
              "         total_steps: 25000\n",
              "         warmup_learning_rate: 0.013333000242710114\n",
              "         warmup_steps: 2000\n",
              "       }\n",
              "     }\n",
              "     momentum_optimizer_value: 0.8999999761581421\n",
              "   }\n",
              "   use_moving_average: false\n",
              " }\n",
              " fine_tune_checkpoint: \"PATH_TO_BE_CONFIGURED\"\n",
              " num_steps: 25000\n",
              " startup_delay_steps: 0.0\n",
              " replicas_to_aggregate: 8\n",
              " max_number_of_boxes: 100\n",
              " unpad_groundtruth_tensors: false\n",
              " fine_tune_checkpoint_type: \"classification\"\n",
              " use_bfloat16: true\n",
              " fine_tune_checkpoint_version: V2, 'train_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED/label_map.txt\"\n",
              " tf_record_input_reader {\n",
              "   input_path: \"PATH_TO_BE_CONFIGURED/train2017-?????-of-00256.tfrecord\"\n",
              " }, 'eval_config': metrics_set: \"coco_detection_metrics\"\n",
              " use_moving_averages: false\n",
              " batch_size: 1, 'eval_input_configs': [label_map_path: \"PATH_TO_BE_CONFIGURED/label_map.txt\"\n",
              " shuffle: false\n",
              " num_epochs: 1\n",
              " tf_record_input_reader {\n",
              "   input_path: \"PATH_TO_BE_CONFIGURED/val2017-?????-of-00032.tfrecord\"\n",
              " }\n",
              " ], 'eval_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED/label_map.txt\"\n",
              " shuffle: false\n",
              " num_epochs: 1\n",
              " tf_record_input_reader {\n",
              "   input_path: \"PATH_TO_BE_CONFIGURED/val2017-?????-of-00032.tfrecord\"\n",
              " }}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "5Iuk882cFR5h",
        "outputId": "802bfa70-0802-4797-cef7-db2d7cdea5a2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'drive/MyDrive/Tensorflow/workspace/pre-trained-models1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "paths['PRETRAINED_MODEL_PATH']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vK5lotDpfDF"
      },
      "outputs": [],
      "source": [
        "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
        "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"r\") as f:\n",
        "    proto_str = f.read()\n",
        "    text_format.Merge(proto_str, pipeline_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rP43Ph0JpfDG"
      },
      "outputs": [],
      "source": [
        "pipeline_config.model.faster_rcnn.num_classes = len(labels)\n",
        "pipeline_config.train_config.batch_size = 4\n",
        "pipeline_config.train_config.fine_tune_checkpoint = os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0')\n",
        "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
        "pipeline_config.train_input_reader.label_map_path= files['LABELMAP']\n",
        "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'train.record')]\n",
        "pipeline_config.eval_input_reader[0].label_map_path = files['LABELMAP']\n",
        "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'test.record')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJvfgwWqpfDG"
      },
      "outputs": [],
      "source": [
        "config_text = text_format.MessageToString(pipeline_config)\n",
        "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"wb\") as f:\n",
        "    f.write(config_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKiFRKJoFR5h",
        "outputId": "4166d808-4a86-41cf-8dbc-bafccbe25577"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "model {\n",
              "  faster_rcnn {\n",
              "    num_classes: 31\n",
              "    image_resizer {\n",
              "      keep_aspect_ratio_resizer {\n",
              "        min_dimension: 640\n",
              "        max_dimension: 640\n",
              "        pad_to_max_dimension: true\n",
              "      }\n",
              "    }\n",
              "    feature_extractor {\n",
              "      type: \"faster_rcnn_resnet152_keras\"\n",
              "      batch_norm_trainable: true\n",
              "    }\n",
              "    first_stage_anchor_generator {\n",
              "      grid_anchor_generator {\n",
              "        height_stride: 16\n",
              "        width_stride: 16\n",
              "        scales: 0.25\n",
              "        scales: 0.5\n",
              "        scales: 1.0\n",
              "        scales: 2.0\n",
              "        aspect_ratios: 0.5\n",
              "        aspect_ratios: 1.0\n",
              "        aspect_ratios: 2.0\n",
              "      }\n",
              "    }\n",
              "    first_stage_box_predictor_conv_hyperparams {\n",
              "      op: CONV\n",
              "      regularizer {\n",
              "        l2_regularizer {\n",
              "          weight: 0.0\n",
              "        }\n",
              "      }\n",
              "      initializer {\n",
              "        truncated_normal_initializer {\n",
              "          stddev: 0.009999999776482582\n",
              "        }\n",
              "      }\n",
              "    }\n",
              "    first_stage_nms_score_threshold: 0.0\n",
              "    first_stage_nms_iou_threshold: 0.699999988079071\n",
              "    first_stage_max_proposals: 300\n",
              "    first_stage_localization_loss_weight: 2.0\n",
              "    first_stage_objectness_loss_weight: 1.0\n",
              "    initial_crop_size: 14\n",
              "    maxpool_kernel_size: 2\n",
              "    maxpool_stride: 2\n",
              "    second_stage_box_predictor {\n",
              "      mask_rcnn_box_predictor {\n",
              "        fc_hyperparams {\n",
              "          op: FC\n",
              "          regularizer {\n",
              "            l2_regularizer {\n",
              "              weight: 0.0\n",
              "            }\n",
              "          }\n",
              "          initializer {\n",
              "            variance_scaling_initializer {\n",
              "              factor: 1.0\n",
              "              uniform: true\n",
              "              mode: FAN_AVG\n",
              "            }\n",
              "          }\n",
              "        }\n",
              "        use_dropout: false\n",
              "        dropout_keep_probability: 1.0\n",
              "        share_box_across_classes: true\n",
              "      }\n",
              "    }\n",
              "    second_stage_post_processing {\n",
              "      batch_non_max_suppression {\n",
              "        score_threshold: 0.0\n",
              "        iou_threshold: 0.6000000238418579\n",
              "        max_detections_per_class: 100\n",
              "        max_total_detections: 300\n",
              "      }\n",
              "      score_converter: SOFTMAX\n",
              "    }\n",
              "    second_stage_localization_loss_weight: 2.0\n",
              "    second_stage_classification_loss_weight: 1.0\n",
              "    use_matmul_crop_and_resize: true\n",
              "    clip_anchors_to_image: true\n",
              "    use_matmul_gather_in_matcher: true\n",
              "    use_static_balanced_label_sampler: true\n",
              "    use_static_shapes: true\n",
              "  }\n",
              "}\n",
              "train_config {\n",
              "  batch_size: 4\n",
              "  data_augmentation_options {\n",
              "    random_horizontal_flip {\n",
              "    }\n",
              "  }\n",
              "  sync_replicas: true\n",
              "  optimizer {\n",
              "    momentum_optimizer {\n",
              "      learning_rate {\n",
              "        cosine_decay_learning_rate {\n",
              "          learning_rate_base: 0.03999999910593033\n",
              "          total_steps: 25000\n",
              "          warmup_learning_rate: 0.013333000242710114\n",
              "          warmup_steps: 2000\n",
              "        }\n",
              "      }\n",
              "      momentum_optimizer_value: 0.8999999761581421\n",
              "    }\n",
              "    use_moving_average: false\n",
              "  }\n",
              "  fine_tune_checkpoint: \"drive/MyDrive/Tensorflow/workspace/pre-trained-models1/faster_rcnn_resnet152_v1_640x640_coco17_tpu-8/checkpoint/ckpt-0\"\n",
              "  num_steps: 25000\n",
              "  startup_delay_steps: 0.0\n",
              "  replicas_to_aggregate: 8\n",
              "  max_number_of_boxes: 100\n",
              "  unpad_groundtruth_tensors: false\n",
              "  fine_tune_checkpoint_type: \"detection\"\n",
              "  use_bfloat16: true\n",
              "  fine_tune_checkpoint_version: V2\n",
              "}\n",
              "train_input_reader {\n",
              "  label_map_path: \"drive/MyDrive/Tensorflow/workspace/annotations/label_map.pbtxt\"\n",
              "  tf_record_input_reader {\n",
              "    input_path: \"drive/MyDrive/Tensorflow/workspace/annotations/train.record\"\n",
              "  }\n",
              "}\n",
              "eval_config {\n",
              "  metrics_set: \"coco_detection_metrics\"\n",
              "  use_moving_averages: false\n",
              "  batch_size: 1\n",
              "}\n",
              "eval_input_reader {\n",
              "  label_map_path: \"drive/MyDrive/Tensorflow/workspace/annotations/label_map.pbtxt\"\n",
              "  shuffle: false\n",
              "  num_epochs: 1\n",
              "  tf_record_input_reader {\n",
              "    input_path: \"drive/MyDrive/Tensorflow/workspace/annotations/test.record\"\n",
              "  }\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "pipeline_config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zr3ON7xMpfDG"
      },
      "source": [
        "# 6. Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-Y2UQmQpfDG"
      },
      "outputs": [],
      "source": [
        "TRAINING_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wT582z4I9rV",
        "outputId": "e9ff3865-40ca-4ae3-801b-569f17b946a3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['label_map.pbtxt', 'test.record', 'train.record']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "os.listdir(paths['ANNOTATION_PATH'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jMP2XDfQpfDH"
      },
      "outputs": [],
      "source": [
        "command = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps=2900\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K5GPJ6IbFR5i",
        "outputId": "233b131f-3e67-4d35-c37e-cfb77b1a328d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Package                       Version     Editable project location\n",
            "----------------------------- ----------- -----------------------------------------------------------------------------------------\n",
            "absl-py                       1.3.0\n",
            "anyio                         3.6.2\n",
            "apache-beam                   2.44.0rc1\n",
            "argon2-cffi                   21.3.0\n",
            "argon2-cffi-bindings          21.2.0\n",
            "arrow                         1.2.3\n",
            "asttokens                     2.2.1\n",
            "astunparse                    1.6.3\n",
            "attrs                         22.1.0\n",
            "avro-python3                  1.10.2\n",
            "backcall                      0.2.0\n",
            "beautifulsoup4                4.11.1\n",
            "bleach                        5.0.1\n",
            "cachetools                    5.2.0\n",
            "certifi                       2022.12.7\n",
            "cffi                          1.15.1\n",
            "charset-normalizer            2.1.1\n",
            "colorama                      0.4.6\n",
            "comm                          0.1.2\n",
            "contextlib2                   21.6.0\n",
            "contourpy                     1.0.6\n",
            "cycler                        0.11.0\n",
            "Cython                        0.29.32\n",
            "debugpy                       1.6.4\n",
            "decorator                     5.1.1\n",
            "defusedxml                    0.7.1\n",
            "dill                          0.3.6\n",
            "dm-tree                       0.1.7\n",
            "entrypoints                   0.4\n",
            "etils                         0.9.0\n",
            "executing                     1.2.0\n",
            "fastjsonschema                2.16.2\n",
            "flatbuffers                   22.12.6\n",
            "fonttools                     4.38.0\n",
            "fqdn                          1.5.1\n",
            "gast                          0.4.0\n",
            "gin                           0.1.6\n",
            "gin-config                    0.1.1\n",
            "google-api-core               2.11.0\n",
            "google-api-python-client      2.70.0\n",
            "google-auth                   2.15.0\n",
            "google-auth-httplib2          0.1.0\n",
            "google-auth-oauthlib          0.4.6\n",
            "google-pasta                  0.2.0\n",
            "googleapis-common-protos      1.57.0\n",
            "grpcio                        1.51.1\n",
            "h5py                          3.7.0\n",
            "httplib2                      0.21.0\n",
            "idna                          3.4\n",
            "immutabledict                 2.2.3\n",
            "importlib-metadata            5.1.0\n",
            "importlib-resources           5.10.1\n",
            "ipykernel                     6.19.2\n",
            "ipython                       8.7.0\n",
            "ipython-genutils              0.2.0\n",
            "ipywidgets                    8.0.3\n",
            "isoduration                   20.11.0\n",
            "jedi                          0.18.2\n",
            "Jinja2                        3.1.2\n",
            "joblib                        1.2.0\n",
            "jsonpointer                   2.3\n",
            "jsonschema                    4.17.3\n",
            "jupyter                       1.0.0\n",
            "jupyter_client                7.4.8\n",
            "jupyter-console               6.4.4\n",
            "jupyter_core                  5.1.0\n",
            "jupyter-events                0.5.0\n",
            "jupyter_server                2.0.1\n",
            "jupyter_server_terminals      0.4.2\n",
            "jupyterlab-pygments           0.2.2\n",
            "jupyterlab-widgets            3.0.4\n",
            "kaggle                        1.5.12\n",
            "keras                         2.10.0\n",
            "Keras-Preprocessing           1.1.2\n",
            "kiwisolver                    1.4.4\n",
            "libclang                      14.0.6\n",
            "lvis                          0.5.3\n",
            "lxml                          4.9.2\n",
            "Markdown                      3.4.1\n",
            "MarkupSafe                    2.1.1\n",
            "matplotlib                    3.6.2\n",
            "matplotlib-inline             0.1.6\n",
            "mistune                       2.0.4\n",
            "nbclassic                     0.4.8\n",
            "nbclient                      0.7.2\n",
            "nbconvert                     7.2.6\n",
            "nbformat                      5.7.0\n",
            "nest-asyncio                  1.5.6\n",
            "notebook                      6.5.2\n",
            "notebook_shim                 0.2.2\n",
            "numpy                         1.23.5\n",
            "oauth2client                  4.1.3\n",
            "oauthlib                      3.2.2\n",
            "object-detection              0.0.3\n",
            "objsize                       0.6.1\n",
            "opencv-python                 4.6.0.66\n",
            "opencv-python-headless        4.6.0.66\n",
            "opt-einsum                    3.3.0\n",
            "orjson                        3.8.4\n",
            "packaging                     22.0\n",
            "pandas                        1.5.2\n",
            "pandocfilters                 1.5.0\n",
            "parso                         0.8.3\n",
            "pickleshare                   0.7.5\n",
            "Pillow                        9.3.0\n",
            "pip                           22.3.1\n",
            "platformdirs                  2.6.0\n",
            "portalocker                   2.6.0\n",
            "prometheus-client             0.15.0\n",
            "promise                       2.3\n",
            "prompt-toolkit                3.0.36\n",
            "proto-plus                    1.22.2\n",
            "protobuf                      3.19.6\n",
            "psutil                        5.9.4\n",
            "pure-eval                     0.2.2\n",
            "py-cpuinfo                    9.0.0\n",
            "pyarrow                       9.0.0\n",
            "pyasn1                        0.4.8\n",
            "pyasn1-modules                0.2.8\n",
            "pycocotools                   2.0.6\n",
            "pycparser                     2.21\n",
            "pydot                         1.4.2\n",
            "Pygments                      2.13.0\n",
            "pymongo                       3.13.0\n",
            "pyparsing                     3.0.9\n",
            "PyQt5                         5.15.7\n",
            "PyQt5-Qt5                     5.15.2\n",
            "PyQt5-sip                     12.11.0\n",
            "pyrsistent                    0.19.2\n",
            "python-dateutil               2.8.2\n",
            "python-json-logger            2.0.4\n",
            "python-slugify                7.0.0\n",
            "pytz                          2022.6\n",
            "pywin32                       305\n",
            "pywinpty                      2.0.9\n",
            "PyYAML                        5.4.1\n",
            "pyzmq                         24.0.1\n",
            "qtconsole                     5.4.0\n",
            "QtPy                          2.3.0\n",
            "regex                         2022.10.31\n",
            "requests                      2.28.1\n",
            "requests-oauthlib             1.3.1\n",
            "rfc3339-validator             0.1.4\n",
            "rfc3986-validator             0.1.1\n",
            "rsa                           4.9\n",
            "sacrebleu                     2.2.0\n",
            "scikit-learn                  1.2.0\n",
            "scipy                         1.9.3\n",
            "Send2Trash                    1.8.0\n",
            "sentencepiece                 0.1.97\n",
            "seqeval                       1.2.2\n",
            "setuptools                    49.2.1\n",
            "six                           1.16.0\n",
            "slim                          0.1         c:\\users\\mounikag\\waisl_work\\tensorflow_object\\tfodcourse\\tensorflow\\models\\research\\slim\n",
            "sniffio                       1.3.0\n",
            "soupsieve                     2.3.2.post1\n",
            "split-folders                 0.5.1\n",
            "stack-data                    0.6.2\n",
            "tabulate                      0.9.0\n",
            "tensorboard                   2.10.1\n",
            "tensorboard-data-server       0.6.1\n",
            "tensorboard-plugin-wit        1.8.1\n",
            "tensorflow                    2.10.1\n",
            "tensorflow-addons             0.19.0\n",
            "tensorflow-datasets           4.7.0\n",
            "tensorflow-estimator          2.10.0\n",
            "tensorflow-gpu                2.10.1\n",
            "tensorflow-hub                0.12.0\n",
            "tensorflow-intel              2.11.0\n",
            "tensorflow-io                 0.28.0\n",
            "tensorflow-io-gcs-filesystem  0.28.0\n",
            "tensorflow-metadata           1.12.0\n",
            "tensorflow-model-optimization 0.7.3\n",
            "tensorflow-text               2.10.0\n",
            "termcolor                     2.1.1\n",
            "terminado                     0.17.1\n",
            "text-unidecode                1.3\n",
            "tf-models-official            2.10.1\n",
            "tf-slim                       1.1.0\n",
            "threadpoolctl                 3.1.0\n",
            "tinycss2                      1.2.1\n",
            "toml                          0.10.2\n",
            "tornado                       6.2\n",
            "tqdm                          4.64.1\n",
            "traitlets                     5.7.1\n",
            "typeguard                     2.13.3\n",
            "typing_extensions             4.4.0\n",
            "uri-template                  1.2.0\n",
            "uritemplate                   4.1.1\n",
            "urllib3                       1.26.13\n",
            "wcwidth                       0.2.5\n",
            "webcolors                     1.12\n",
            "webencodings                  0.5.1\n",
            "websocket-client              1.4.2\n",
            "Werkzeug                      2.2.2\n",
            "wget                          3.2\n",
            "wheel                         0.38.4\n",
            "widgetsnbextension            4.0.4\n",
            "wrapt                         1.14.1\n",
            "zipp                          3.11.0\n",
            "zstandard                     0.19.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BYJSqT4jFR5i",
        "outputId": "3baa2e68-d9cd-42a5-9a01-4f303eb11f93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.10.1\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4OXXi-ApfDH",
        "outputId": "3a3a8180-1cfa-4b6b-8530-038c8a77f70c",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python drive/MyDrive/Tensorflow/models/research/object_detection/model_main_tf2.py --model_dir=drive/MyDrive/Tensorflow/workspace/models2/my_faster_rcnn --pipeline_config_path=drive/MyDrive/Tensorflow/workspace/models2/my_faster_rcnn/pipeline.config --num_train_steps=2900\n"
          ]
        }
      ],
      "source": [
        "print(command)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3ZsJR-qpfDH",
        "outputId": "00b50a7d-879f-4714-a2a0-81a168c32ff4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-02-14 17:22:04.011695: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-02-14 17:22:04.011816: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-02-14 17:22:04.011842: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-02-14 17:22:09.050644: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "I0214 17:22:09.071656 139704219883328 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "INFO:tensorflow:Maybe overwriting train_steps: 2900\n",
            "I0214 17:22:09.077771 139704219883328 config_util.py:552] Maybe overwriting train_steps: 2900\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0214 17:22:09.077962 139704219883328 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "W0214 17:22:09.111614 139704219883328 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "INFO:tensorflow:Reading unweighted datasets: ['drive/MyDrive/Tensorflow/workspace/annotations/train.record']\n",
            "I0214 17:22:09.132708 139704219883328 dataset_builder.py:162] Reading unweighted datasets: ['drive/MyDrive/Tensorflow/workspace/annotations/train.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['drive/MyDrive/Tensorflow/workspace/annotations/train.record']\n",
            "I0214 17:22:09.133122 139704219883328 dataset_builder.py:79] Reading record datasets for input file: ['drive/MyDrive/Tensorflow/workspace/annotations/train.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0214 17:22:09.133261 139704219883328 dataset_builder.py:80] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0214 17:22:09.133327 139704219883328 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "W0214 17:22:09.141489 139704219883328 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0214 17:22:09.159087 139704219883328 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
            "W0214 17:22:09.705701 139704219883328 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0214 17:22:15.246013 139704219883328 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0214 17:22:17.698137 139704219883328 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "/usr/local/lib/python3.8/dist-packages/keras/backend.py:451: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn(\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0214 17:22:32.936178 139699625088768 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py:459: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use ref() instead.\n",
            "W0214 17:22:43.358430 139699625088768 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py:459: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use ref() instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "W0214 17:22:48.032655 139699625088768 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "2023-02-14 17:23:15.070781: W tensorflow/tsl/framework/bfc_allocator.cc:360] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0214 17:23:24.872593 139704219883328 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0214 17:23:24.876438 139704219883328 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0214 17:23:24.877897 139704219883328 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0214 17:23:24.879183 139704219883328 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0214 17:23:24.883542 139704219883328 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0214 17:23:24.884674 139704219883328 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0214 17:23:24.885849 139704219883328 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0214 17:23:24.889864 139704219883328 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0214 17:23:24.894330 139704219883328 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0214 17:23:24.895541 139704219883328 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "W0214 17:23:28.925645 139698584389376 deprecation.py:554] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "INFO:tensorflow:Step 100 per-step time 2.124s\n",
            "I0214 17:27:00.658314 139704219883328 model_lib_v2.py:705] Step 100 per-step time 2.124s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.1155873,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.23274972,\n",
            " 'Loss/RPNLoss/localization_loss': 0.011285847,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.0027873155,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.3624102,\n",
            " 'learning_rate': 0.014666351}\n",
            "I0214 17:27:00.658750 139704219883328 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.1155873,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.23274972,\n",
            " 'Loss/RPNLoss/localization_loss': 0.011285847,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.0027873155,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.3624102,\n",
            " 'learning_rate': 0.014666351}\n",
            "INFO:tensorflow:Step 200 per-step time 1.145s\n",
            "I0214 17:28:55.092118 139704219883328 model_lib_v2.py:705] Step 200 per-step time 1.145s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.10393817,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.09937181,\n",
            " 'Loss/RPNLoss/localization_loss': 0.008025817,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.003079108,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.21441491,\n",
            " 'learning_rate': 0.0159997}\n",
            "I0214 17:28:55.092513 139704219883328 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.10393817,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.09937181,\n",
            " 'Loss/RPNLoss/localization_loss': 0.008025817,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.003079108,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.21441491,\n",
            " 'learning_rate': 0.0159997}\n",
            "INFO:tensorflow:Step 300 per-step time 1.154s\n",
            "I0214 17:30:50.491536 139704219883328 model_lib_v2.py:705] Step 300 per-step time 1.154s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.20106651,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.23105189,\n",
            " 'Loss/RPNLoss/localization_loss': 0.04451155,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.028888285,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.50551826,\n",
            " 'learning_rate': 0.01733305}\n",
            "I0214 17:30:50.491930 139704219883328 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.20106651,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.23105189,\n",
            " 'Loss/RPNLoss/localization_loss': 0.04451155,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.028888285,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.50551826,\n",
            " 'learning_rate': 0.01733305}\n",
            "INFO:tensorflow:Step 400 per-step time 1.152s\n",
            "I0214 17:32:45.704326 139704219883328 model_lib_v2.py:705] Step 400 per-step time 1.152s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.08466943,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.10699708,\n",
            " 'Loss/RPNLoss/localization_loss': 0.019079065,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.009285001,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.22003058,\n",
            " 'learning_rate': 0.0186664}\n",
            "I0214 17:32:45.704751 139704219883328 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.08466943,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.10699708,\n",
            " 'Loss/RPNLoss/localization_loss': 0.019079065,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.009285001,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.22003058,\n",
            " 'learning_rate': 0.0186664}\n",
            "INFO:tensorflow:Step 500 per-step time 1.154s\n",
            "I0214 17:34:41.071004 139704219883328 model_lib_v2.py:705] Step 500 per-step time 1.154s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.16922927,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.11209631,\n",
            " 'Loss/RPNLoss/localization_loss': 0.10148448,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.053969964,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.43678004,\n",
            " 'learning_rate': 0.01999975}\n",
            "I0214 17:34:41.071403 139704219883328 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.16922927,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.11209631,\n",
            " 'Loss/RPNLoss/localization_loss': 0.10148448,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.053969964,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.43678004,\n",
            " 'learning_rate': 0.01999975}\n",
            "INFO:tensorflow:Step 600 per-step time 1.155s\n",
            "I0214 17:36:36.556971 139704219883328 model_lib_v2.py:705] Step 600 per-step time 1.155s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.12182947,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.046213303,\n",
            " 'Loss/RPNLoss/localization_loss': 0.13311319,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.023834005,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.32498997,\n",
            " 'learning_rate': 0.0213331}\n",
            "I0214 17:36:36.557390 139704219883328 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.12182947,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.046213303,\n",
            " 'Loss/RPNLoss/localization_loss': 0.13311319,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.023834005,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.32498997,\n",
            " 'learning_rate': 0.0213331}\n",
            "INFO:tensorflow:Step 700 per-step time 1.153s\n",
            "I0214 17:38:31.866912 139704219883328 model_lib_v2.py:705] Step 700 per-step time 1.153s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.06955131,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.06425629,\n",
            " 'Loss/RPNLoss/localization_loss': 0.01885029,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.031558964,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.18421686,\n",
            " 'learning_rate': 0.02266645}\n",
            "I0214 17:38:31.867334 139704219883328 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.06955131,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.06425629,\n",
            " 'Loss/RPNLoss/localization_loss': 0.01885029,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.031558964,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.18421686,\n",
            " 'learning_rate': 0.02266645}\n",
            "INFO:tensorflow:Step 800 per-step time 1.152s\n",
            "I0214 17:40:27.101167 139704219883328 model_lib_v2.py:705] Step 800 per-step time 1.152s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.07863703,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.119552605,\n",
            " 'Loss/RPNLoss/localization_loss': 0.018409038,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.0047520045,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.22135068,\n",
            " 'learning_rate': 0.023999799}\n",
            "I0214 17:40:27.101595 139704219883328 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.07863703,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.119552605,\n",
            " 'Loss/RPNLoss/localization_loss': 0.018409038,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.0047520045,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.22135068,\n",
            " 'learning_rate': 0.023999799}\n",
            "INFO:tensorflow:Step 900 per-step time 1.150s\n",
            "I0214 17:42:22.132014 139704219883328 model_lib_v2.py:705] Step 900 per-step time 1.150s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.04370687,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.10988229,\n",
            " 'Loss/RPNLoss/localization_loss': 0.005807706,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.0019903602,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.16138723,\n",
            " 'learning_rate': 0.025333151}\n",
            "I0214 17:42:22.132431 139704219883328 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.04370687,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.10988229,\n",
            " 'Loss/RPNLoss/localization_loss': 0.005807706,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.0019903602,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.16138723,\n",
            " 'learning_rate': 0.025333151}\n",
            "INFO:tensorflow:Step 1000 per-step time 1.148s\n",
            "I0214 17:44:16.959774 139704219883328 model_lib_v2.py:705] Step 1000 per-step time 1.148s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.062387522,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.2801903,\n",
            " 'Loss/RPNLoss/localization_loss': 0.010231275,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.007213302,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.3600224,\n",
            " 'learning_rate': 0.0266665}\n",
            "I0214 17:44:16.960087 139704219883328 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.062387522,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.2801903,\n",
            " 'Loss/RPNLoss/localization_loss': 0.010231275,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.007213302,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.3600224,\n",
            " 'learning_rate': 0.0266665}\n",
            "INFO:tensorflow:Step 1100 per-step time 1.193s\n",
            "I0214 17:46:16.304208 139704219883328 model_lib_v2.py:705] Step 1100 per-step time 1.193s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.076506734,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.11395113,\n",
            " 'Loss/RPNLoss/localization_loss': 0.018330978,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.0077493815,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.21653822,\n",
            " 'learning_rate': 0.02799985}\n",
            "I0214 17:46:16.304622 139704219883328 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.076506734,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.11395113,\n",
            " 'Loss/RPNLoss/localization_loss': 0.018330978,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.0077493815,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.21653822,\n",
            " 'learning_rate': 0.02799985}\n",
            "INFO:tensorflow:Step 1200 per-step time 1.144s\n",
            "I0214 17:48:10.679224 139704219883328 model_lib_v2.py:705] Step 1200 per-step time 1.144s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.123527065,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.16074413,\n",
            " 'Loss/RPNLoss/localization_loss': 0.0027173292,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.002673928,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.28966245,\n",
            " 'learning_rate': 0.0293332}\n",
            "I0214 17:48:10.679538 139704219883328 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.123527065,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.16074413,\n",
            " 'Loss/RPNLoss/localization_loss': 0.0027173292,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.002673928,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.28966245,\n",
            " 'learning_rate': 0.0293332}\n",
            "INFO:tensorflow:Step 1300 per-step time 1.148s\n",
            "I0214 17:50:05.505236 139704219883328 model_lib_v2.py:705] Step 1300 per-step time 1.148s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.03271686,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.07457665,\n",
            " 'Loss/RPNLoss/localization_loss': 0.015689086,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.007048386,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.13003097,\n",
            " 'learning_rate': 0.03066655}\n",
            "I0214 17:50:05.505579 139704219883328 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.03271686,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.07457665,\n",
            " 'Loss/RPNLoss/localization_loss': 0.015689086,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.007048386,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.13003097,\n",
            " 'learning_rate': 0.03066655}\n",
            "INFO:tensorflow:Step 1400 per-step time 1.145s\n",
            "I0214 17:51:59.989776 139704219883328 model_lib_v2.py:705] Step 1400 per-step time 1.145s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.08475044,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.11703837,\n",
            " 'Loss/RPNLoss/localization_loss': 0.0120914,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.004754854,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.21863507,\n",
            " 'learning_rate': 0.0319999}\n",
            "I0214 17:51:59.990086 139704219883328 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.08475044,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.11703837,\n",
            " 'Loss/RPNLoss/localization_loss': 0.0120914,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.004754854,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.21863507,\n",
            " 'learning_rate': 0.0319999}\n",
            "INFO:tensorflow:Step 1500 per-step time 1.150s\n",
            "I0214 17:53:54.973822 139704219883328 model_lib_v2.py:705] Step 1500 per-step time 1.150s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.06869571,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.07595251,\n",
            " 'Loss/RPNLoss/localization_loss': 0.0025179964,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.0008053124,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.14797153,\n",
            " 'learning_rate': 0.03333325}\n",
            "I0214 17:53:54.974134 139704219883328 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.06869571,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.07595251,\n",
            " 'Loss/RPNLoss/localization_loss': 0.0025179964,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.0008053124,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.14797153,\n",
            " 'learning_rate': 0.03333325}\n",
            "INFO:tensorflow:Step 1600 per-step time 1.142s\n",
            "I0214 17:55:49.206034 139704219883328 model_lib_v2.py:705] Step 1600 per-step time 1.142s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.09242709,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.11374173,\n",
            " 'Loss/RPNLoss/localization_loss': 0.17079224,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.04522039,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.42218143,\n",
            " 'learning_rate': 0.034666598}\n",
            "I0214 17:55:49.206349 139704219883328 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.09242709,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.11374173,\n",
            " 'Loss/RPNLoss/localization_loss': 0.17079224,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.04522039,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.42218143,\n",
            " 'learning_rate': 0.034666598}\n",
            "INFO:tensorflow:Step 1700 per-step time 1.148s\n",
            "I0214 17:57:43.958785 139704219883328 model_lib_v2.py:705] Step 1700 per-step time 1.148s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.046031486,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.08793016,\n",
            " 'Loss/RPNLoss/localization_loss': 0.0024351913,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.0003238864,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.13672072,\n",
            " 'learning_rate': 0.03599995}\n",
            "I0214 17:57:43.959097 139704219883328 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.046031486,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.08793016,\n",
            " 'Loss/RPNLoss/localization_loss': 0.0024351913,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.0003238864,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.13672072,\n",
            " 'learning_rate': 0.03599995}\n",
            "INFO:tensorflow:Step 1800 per-step time 1.144s\n",
            "I0214 17:59:38.386289 139704219883328 model_lib_v2.py:705] Step 1800 per-step time 1.144s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.06295888,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.04932139,\n",
            " 'Loss/RPNLoss/localization_loss': 0.013200347,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.002058672,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.12753929,\n",
            " 'learning_rate': 0.037333302}\n",
            "I0214 17:59:38.386619 139704219883328 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.06295888,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.04932139,\n",
            " 'Loss/RPNLoss/localization_loss': 0.013200347,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.002058672,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.12753929,\n",
            " 'learning_rate': 0.037333302}\n",
            "INFO:tensorflow:Step 1900 per-step time 1.140s\n",
            "I0214 18:01:32.368973 139704219883328 model_lib_v2.py:705] Step 1900 per-step time 1.140s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.13876982,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.07984172,\n",
            " 'Loss/RPNLoss/localization_loss': 0.00510154,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.0022528896,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.22596598,\n",
            " 'learning_rate': 0.03866665}\n",
            "I0214 18:01:32.369305 139704219883328 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.13876982,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.07984172,\n",
            " 'Loss/RPNLoss/localization_loss': 0.00510154,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.0022528896,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.22596598,\n",
            " 'learning_rate': 0.03866665}\n",
            "INFO:tensorflow:Step 2000 per-step time 1.140s\n",
            "I0214 18:03:26.416807 139704219883328 model_lib_v2.py:705] Step 2000 per-step time 1.140s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.08801617,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.18441904,\n",
            " 'Loss/RPNLoss/localization_loss': 0.005609647,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.0017822207,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.27982706,\n",
            " 'learning_rate': 0.04}\n",
            "I0214 18:03:26.417112 139704219883328 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.08801617,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.18441904,\n",
            " 'Loss/RPNLoss/localization_loss': 0.005609647,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.0017822207,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.27982706,\n",
            " 'learning_rate': 0.04}\n",
            "INFO:tensorflow:Step 2100 per-step time 1.189s\n",
            "I0214 18:05:25.338067 139704219883328 model_lib_v2.py:705] Step 2100 per-step time 1.189s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.0446255,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.07476927,\n",
            " 'Loss/RPNLoss/localization_loss': 0.0036720433,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.0014238893,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.1244907,\n",
            " 'learning_rate': 0.039998136}\n",
            "I0214 18:05:25.338404 139704219883328 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.0446255,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.07476927,\n",
            " 'Loss/RPNLoss/localization_loss': 0.0036720433,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.0014238893,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.1244907,\n",
            " 'learning_rate': 0.039998136}\n",
            "INFO:tensorflow:Step 2200 per-step time 1.138s\n",
            "I0214 18:07:19.172208 139704219883328 model_lib_v2.py:705] Step 2200 per-step time 1.138s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.3993845,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.06010269,\n",
            " 'Loss/RPNLoss/localization_loss': 0.0028281547,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.0009365008,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.46325183,\n",
            " 'learning_rate': 0.039992537}\n",
            "I0214 18:07:19.172547 139704219883328 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.3993845,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.06010269,\n",
            " 'Loss/RPNLoss/localization_loss': 0.0028281547,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.0009365008,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.46325183,\n",
            " 'learning_rate': 0.039992537}\n",
            "INFO:tensorflow:Step 2300 per-step time 1.143s\n",
            "I0214 18:09:13.474640 139704219883328 model_lib_v2.py:705] Step 2300 per-step time 1.143s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.045918584,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.1548795,\n",
            " 'Loss/RPNLoss/localization_loss': 0.006792727,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.002250419,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.20984122,\n",
            " 'learning_rate': 0.03998321}\n",
            "I0214 18:09:13.474946 139704219883328 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.045918584,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.1548795,\n",
            " 'Loss/RPNLoss/localization_loss': 0.006792727,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.002250419,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.20984122,\n",
            " 'learning_rate': 0.03998321}\n",
            "INFO:tensorflow:Step 2400 per-step time 1.147s\n",
            "I0214 18:11:08.128545 139704219883328 model_lib_v2.py:705] Step 2400 per-step time 1.147s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.07483181,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.07573345,\n",
            " 'Loss/RPNLoss/localization_loss': 0.0349331,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.005376733,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.19087511,\n",
            " 'learning_rate': 0.039970152}\n",
            "I0214 18:11:08.128861 139704219883328 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.07483181,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.07573345,\n",
            " 'Loss/RPNLoss/localization_loss': 0.0349331,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.005376733,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.19087511,\n",
            " 'learning_rate': 0.039970152}\n",
            "INFO:tensorflow:Step 2500 per-step time 1.145s\n",
            "I0214 18:13:02.597481 139704219883328 model_lib_v2.py:705] Step 2500 per-step time 1.145s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.07483932,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.09490357,\n",
            " 'Loss/RPNLoss/localization_loss': 0.0038016634,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.003182142,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.1767267,\n",
            " 'learning_rate': 0.039953373}\n",
            "I0214 18:13:02.597790 139704219883328 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.07483932,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.09490357,\n",
            " 'Loss/RPNLoss/localization_loss': 0.0038016634,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.003182142,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.1767267,\n",
            " 'learning_rate': 0.039953373}\n",
            "INFO:tensorflow:Step 2600 per-step time 1.140s\n",
            "I0214 18:14:56.591483 139704219883328 model_lib_v2.py:705] Step 2600 per-step time 1.140s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.13198717,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.14002489,\n",
            " 'Loss/RPNLoss/localization_loss': 0.0063382713,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.00048258915,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.2788329,\n",
            " 'learning_rate': 0.03993287}\n",
            "I0214 18:14:56.591789 139704219883328 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.13198717,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.14002489,\n",
            " 'Loss/RPNLoss/localization_loss': 0.0063382713,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.00048258915,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.2788329,\n",
            " 'learning_rate': 0.03993287}\n",
            "INFO:tensorflow:Step 2700 per-step time 1.145s\n",
            "I0214 18:16:51.085448 139704219883328 model_lib_v2.py:705] Step 2700 per-step time 1.145s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.03994267,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.1432064,\n",
            " 'Loss/RPNLoss/localization_loss': 0.008369462,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.0030921816,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.19461071,\n",
            " 'learning_rate': 0.039908648}\n",
            "I0214 18:16:51.085777 139704219883328 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.03994267,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.1432064,\n",
            " 'Loss/RPNLoss/localization_loss': 0.008369462,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.0030921816,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.19461071,\n",
            " 'learning_rate': 0.039908648}\n",
            "INFO:tensorflow:Step 2800 per-step time 1.146s\n",
            "I0214 18:18:45.672945 139704219883328 model_lib_v2.py:705] Step 2800 per-step time 1.146s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.05473035,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.046775106,\n",
            " 'Loss/RPNLoss/localization_loss': 0.004666362,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.019763801,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.12593561,\n",
            " 'learning_rate': 0.039880715}\n",
            "I0214 18:18:45.673264 139704219883328 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.05473035,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.046775106,\n",
            " 'Loss/RPNLoss/localization_loss': 0.004666362,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.019763801,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.12593561,\n",
            " 'learning_rate': 0.039880715}\n",
            "INFO:tensorflow:Step 2900 per-step time 1.154s\n",
            "I0214 18:20:41.032374 139704219883328 model_lib_v2.py:705] Step 2900 per-step time 1.154s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.102953434,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.110242255,\n",
            " 'Loss/RPNLoss/localization_loss': 0.3530959,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.018111106,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.5844027,\n",
            " 'learning_rate': 0.039849065}\n",
            "I0214 18:20:41.032702 139704219883328 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.102953434,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.110242255,\n",
            " 'Loss/RPNLoss/localization_loss': 0.3530959,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.018111106,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.5844027,\n",
            " 'learning_rate': 0.039849065}\n"
          ]
        }
      ],
      "source": [
        "!{command}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_YRZu7npfDH"
      },
      "source": [
        "# 7. Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OlRt4fadFR5i"
      },
      "outputs": [],
      "source": [
        "EVALUATION_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80L7-fdPpfDH"
      },
      "outputs": [],
      "source": [
        "command = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYsgEPx9pfDH",
        "outputId": "249b0da5-104d-4cbc-c3a0-fdfffee8856e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python drive/MyDrive/Tensorflow/models/research/object_detection/model_main_tf2.py --model_dir=drive/MyDrive/Tensorflow/workspace/models2/my_faster_rcnn --pipeline_config_path=drive/MyDrive/Tensorflow/workspace/models2/my_faster_rcnn/pipeline.config --checkpoint_dir=drive/MyDrive/Tensorflow/workspace/models2/my_faster_rcnn\n"
          ]
        }
      ],
      "source": [
        "print(command)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqTV2jGBpfDH",
        "outputId": "002857ec-ca46-4bf3-dda0-8dbf55ce647a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-02-14 18:21:15.102500: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-02-14 18:21:15.102623: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-02-14 18:21:15.102646: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
            "W0214 18:21:21.696507 140208669906752 model_lib_v2.py:1089] Forced number of epochs for all eval validations to be 1.\n",
            "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: None\n",
            "I0214 18:21:21.696762 140208669906752 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: None\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0214 18:21:21.696850 140208669906752 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
            "I0214 18:21:21.696928 140208669906752 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n",
            "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "W0214 18:21:21.697039 140208669906752 model_lib_v2.py:1106] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "2023-02-14 18:21:23.843267: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['drive/MyDrive/Tensorflow/workspace/annotations/test.record']\n",
            "I0214 18:21:23.927897 140208669906752 dataset_builder.py:162] Reading unweighted datasets: ['drive/MyDrive/Tensorflow/workspace/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['drive/MyDrive/Tensorflow/workspace/annotations/test.record']\n",
            "I0214 18:21:23.928408 140208669906752 dataset_builder.py:79] Reading record datasets for input file: ['drive/MyDrive/Tensorflow/workspace/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0214 18:21:23.928566 140208669906752 dataset_builder.py:80] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0214 18:21:23.928635 140208669906752 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "W0214 18:21:23.932264 140208669906752 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0214 18:21:23.963397 140208669906752 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
            "W0214 18:21:24.537123 140208669906752 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0214 18:21:27.593491 140208669906752 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0214 18:21:28.669140 140208669906752 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Waiting for new checkpoint at drive/MyDrive/Tensorflow/workspace/models2/my_faster_rcnn\n",
            "I0214 18:21:32.496350 140208669906752 checkpoint_utils.py:140] Waiting for new checkpoint at drive/MyDrive/Tensorflow/workspace/models2/my_faster_rcnn\n",
            "INFO:tensorflow:Found new checkpoint at drive/MyDrive/Tensorflow/workspace/models2/my_faster_rcnn/ckpt-3\n",
            "I0214 18:21:32.500494 140208669906752 checkpoint_utils.py:149] Found new checkpoint at drive/MyDrive/Tensorflow/workspace/models2/my_faster_rcnn/ckpt-3\n",
            "/usr/local/lib/python3.8/dist-packages/keras/backend.py:451: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn(\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0214 18:21:46.006411 140208669906752 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py:459: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use ref() instead.\n",
            "W0214 18:21:56.705550 140208669906752 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py:459: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use ref() instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "W0214 18:22:00.955488 140208669906752 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0214 18:22:29.713514 140208669906752 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Finished eval step 0\n",
            "I0214 18:22:29.743028 140208669906752 model_lib_v2.py:966] Finished eval step 0\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py:459: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "W0214 18:22:29.889152 140208669906752 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py:459: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "INFO:tensorflow:Finished eval step 100\n",
            "I0214 18:22:49.547790 140208669906752 model_lib_v2.py:966] Finished eval step 100\n",
            "INFO:tensorflow:Finished eval step 200\n",
            "I0214 18:23:08.407788 140208669906752 model_lib_v2.py:966] Finished eval step 200\n",
            "INFO:tensorflow:Finished eval step 300\n",
            "I0214 18:23:27.596746 140208669906752 model_lib_v2.py:966] Finished eval step 300\n",
            "INFO:tensorflow:Finished eval step 400\n",
            "I0214 18:23:47.118696 140208669906752 model_lib_v2.py:966] Finished eval step 400\n",
            "INFO:tensorflow:Finished eval step 500\n",
            "I0214 18:24:06.542153 140208669906752 model_lib_v2.py:966] Finished eval step 500\n",
            "INFO:tensorflow:Finished eval step 600\n",
            "I0214 18:24:25.890233 140208669906752 model_lib_v2.py:966] Finished eval step 600\n",
            "INFO:tensorflow:Finished eval step 700\n",
            "I0214 18:24:44.674995 140208669906752 model_lib_v2.py:966] Finished eval step 700\n",
            "INFO:tensorflow:Finished eval step 800\n",
            "I0214 18:25:03.610886 140208669906752 model_lib_v2.py:966] Finished eval step 800\n",
            "INFO:tensorflow:Finished eval step 900\n",
            "I0214 18:25:23.001885 140208669906752 model_lib_v2.py:966] Finished eval step 900\n",
            "INFO:tensorflow:Finished eval step 1000\n",
            "I0214 18:25:42.400383 140208669906752 model_lib_v2.py:966] Finished eval step 1000\n",
            "INFO:tensorflow:Finished eval step 1100\n",
            "I0214 18:26:01.865825 140208669906752 model_lib_v2.py:966] Finished eval step 1100\n",
            "INFO:tensorflow:Finished eval step 1200\n",
            "I0214 18:26:21.071898 140208669906752 model_lib_v2.py:966] Finished eval step 1200\n",
            "INFO:tensorflow:Finished eval step 1300\n",
            "I0214 18:26:40.033789 140208669906752 model_lib_v2.py:966] Finished eval step 1300\n",
            "INFO:tensorflow:Finished eval step 1400\n",
            "I0214 18:26:59.400931 140208669906752 model_lib_v2.py:966] Finished eval step 1400\n",
            "INFO:tensorflow:Finished eval step 1500\n",
            "I0214 18:27:18.415504 140208669906752 model_lib_v2.py:966] Finished eval step 1500\n",
            "INFO:tensorflow:Finished eval step 1600\n",
            "I0214 18:27:39.140518 140208669906752 model_lib_v2.py:966] Finished eval step 1600\n",
            "INFO:tensorflow:Finished eval step 1700\n",
            "I0214 18:27:58.694475 140208669906752 model_lib_v2.py:966] Finished eval step 1700\n",
            "INFO:tensorflow:Finished eval step 1800\n",
            "I0214 18:28:18.066061 140208669906752 model_lib_v2.py:966] Finished eval step 1800\n",
            "INFO:tensorflow:Performing evaluation on 1816 images.\n",
            "I0214 18:28:55.288593 140208669906752 coco_evaluation.py:293] Performing evaluation on 1816 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0214 18:28:55.297508 140208669906752 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.39s)\n",
            "I0214 18:28:55.684485 140208669906752 coco_tools.py:138] DONE (t=0.39s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=17.69s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=10.88s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.106\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.219\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.081\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.244\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.114\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.094\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.367\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.454\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.460\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.496\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.470\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.437\n",
            "INFO:tensorflow:Eval metrics at step 2000\n",
            "I0214 18:29:25.324444 140208669906752 model_lib_v2.py:1015] Eval metrics at step 2000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP: 0.105675\n",
            "I0214 18:29:25.334441 140208669906752 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP: 0.105675\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.50IOU: 0.218635\n",
            "I0214 18:29:25.336138 140208669906752 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.50IOU: 0.218635\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.75IOU: 0.081200\n",
            "I0214 18:29:25.337727 140208669906752 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.75IOU: 0.081200\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (small): 0.244443\n",
            "I0214 18:29:25.339220 140208669906752 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (small): 0.244443\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (medium): 0.114483\n",
            "I0214 18:29:25.340641 140208669906752 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (medium): 0.114483\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (large): 0.093699\n",
            "I0214 18:29:25.342287 140208669906752 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (large): 0.093699\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@1: 0.367386\n",
            "I0214 18:29:25.343705 140208669906752 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@1: 0.367386\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@10: 0.453862\n",
            "I0214 18:29:25.345080 140208669906752 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@10: 0.453862\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100: 0.459832\n",
            "I0214 18:29:25.346452 140208669906752 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100: 0.459832\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (small): 0.496479\n",
            "I0214 18:29:25.347903 140208669906752 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (small): 0.496479\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (medium): 0.470426\n",
            "I0214 18:29:25.349348 140208669906752 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (medium): 0.470426\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (large): 0.437210\n",
            "I0214 18:29:25.350965 140208669906752 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (large): 0.437210\n",
            "INFO:tensorflow:\t+ Loss/RPNLoss/localization_loss: 0.145262\n",
            "I0214 18:29:25.352058 140208669906752 model_lib_v2.py:1018] \t+ Loss/RPNLoss/localization_loss: 0.145262\n",
            "INFO:tensorflow:\t+ Loss/RPNLoss/objectness_loss: 0.144009\n",
            "I0214 18:29:25.353202 140208669906752 model_lib_v2.py:1018] \t+ Loss/RPNLoss/objectness_loss: 0.144009\n",
            "INFO:tensorflow:\t+ Loss/BoxClassifierLoss/localization_loss: 0.059319\n",
            "I0214 18:29:25.354245 140208669906752 model_lib_v2.py:1018] \t+ Loss/BoxClassifierLoss/localization_loss: 0.059319\n",
            "INFO:tensorflow:\t+ Loss/BoxClassifierLoss/classification_loss: 0.195903\n",
            "I0214 18:29:25.355266 140208669906752 model_lib_v2.py:1018] \t+ Loss/BoxClassifierLoss/classification_loss: 0.195903\n",
            "INFO:tensorflow:\t+ Loss/regularization_loss: 0.000000\n",
            "I0214 18:29:25.356315 140208669906752 model_lib_v2.py:1018] \t+ Loss/regularization_loss: 0.000000\n",
            "INFO:tensorflow:\t+ Loss/total_loss: 0.544493\n",
            "I0214 18:29:25.357341 140208669906752 model_lib_v2.py:1018] \t+ Loss/total_loss: 0.544493\n",
            "INFO:tensorflow:Waiting for new checkpoint at drive/MyDrive/Tensorflow/workspace/models2/my_faster_rcnn\n",
            "I0214 18:29:25.829799 140208669906752 checkpoint_utils.py:140] Waiting for new checkpoint at drive/MyDrive/Tensorflow/workspace/models2/my_faster_rcnn\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/absl/app.py\", line 308, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/absl/app.py\", line 254, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"drive/MyDrive/Tensorflow/models/research/object_detection/model_main_tf2.py\", line 81, in main\n",
            "    model_lib_v2.eval_continuously(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/object_detection/model_lib_v2.py\", line 1135, in eval_continuously\n",
            "    for latest_checkpoint in tf.train.checkpoints_iterator(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/checkpoint_utils.py\", line 198, in checkpoints_iterator\n",
            "    new_checkpoint_path = wait_for_new_checkpoint(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/checkpoint_utils.py\", line 147, in wait_for_new_checkpoint\n",
            "    time.sleep(seconds_to_sleep)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"drive/MyDrive/Tensorflow/models/research/object_detection/model_main_tf2.py\", line 114, in <module>\n",
            "    tf.compat.v1.app.run()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py\", line 36, in run\n",
            "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/absl/app.py\", line 321, in run\n",
            "    if FLAGS.pdb_post_mortem and sys.stdout.isatty():\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/absl/flags/_flagvalues.py\", line 472, in __getattr__\n",
            "    fl = self._flags()\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!{command}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orvRk02UpfDI"
      },
      "source": [
        "# 8. Load Train Model From Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8TYk4_oIpfDI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from object_detection.builders import model_builder\n",
        "from object_detection.utils import config_util"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-TF4hTUNFR5j",
        "outputId": "3d8e47c8-6150-4e7f-cd4f-c9ee2d1f4943",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'drive/MyDrive/Tensorflow/workspace/models2/my_faster_rcnn'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "paths['CHECKPOINT_PATH']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDnQg-cYpfDI"
      },
      "outputs": [],
      "source": [
        "# Load pipeline config and build a detection model\n",
        "configs = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n",
        "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
        "\n",
        "# Restore checkpoint\n",
        "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
        "ckpt.restore(os.path.join(paths['CHECKPOINT_PATH'], 'ckpt-3')).expect_partial()\n",
        "\n",
        "@tf.function\n",
        "def detect_fn(image):\n",
        "    image, shapes = detection_model.preprocess(image)\n",
        "    prediction_dict = detection_model.predict(image, shapes)\n",
        "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
        "    return detections"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EmsmbBZpfDI"
      },
      "source": [
        "# 9. Detect from an Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_MKiuZ4pfDI"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cBDbIhNapfDI"
      },
      "outputs": [],
      "source": [
        "category_index = label_map_util.create_category_index_from_labelmap(files['LABELMAP'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lx3crOhOzITB"
      },
      "outputs": [],
      "source": [
        "IMAGE_PATH = os.path.join(paths['IMAGE_PATH'], '000744.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "Tpzn1SMry1yK",
        "outputId": "f6b6198c-f017-456e-b629-b30f16eef9b5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "img = cv2.imread(IMAGE_PATH)\n",
        "image_np = np.array(img)\n",
        "\n",
        "input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
        "detections = detect_fn(input_tensor)\n",
        "\n",
        "num_detections = int(detections.pop('num_detections'))\n",
        "detections = {key: value[0, :num_detections].numpy()\n",
        "              for key, value in detections.items()}\n",
        "detections['num_detections'] = num_detections\n",
        "\n",
        "# detection_classes should be ints.\n",
        "detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "label_id_offset = 1\n",
        "image_np_with_detections = image_np.copy()\n",
        "\n",
        "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "            image_np_with_detections,\n",
        "            detections['detection_boxes'],\n",
        "            detections['detection_classes']+label_id_offset,\n",
        "            detections['detection_scores'],\n",
        "            category_index,\n",
        "            use_normalized_coordinates=True,\n",
        "            max_boxes_to_draw=5,\n",
        "            min_score_thresh=.8,\n",
        "            agnostic_mode=False)\n",
        "\n",
        "plt.imshow(cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tH4cj00UFR5k"
      },
      "outputs": [],
      "source": [
        "cap = cv2.VideoCapture(0)\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    image_np = np.array(frame)\n",
        "\n",
        "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
        "    detections = detect_fn(input_tensor)\n",
        "\n",
        "    num_detections = int(detections.pop('num_detections'))\n",
        "    detections = {key: value[0, :num_detections].numpy()\n",
        "                  for key, value in detections.items()}\n",
        "    detections['num_detections'] = num_detections\n",
        "\n",
        "    # detection_classes should be ints.\n",
        "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "    label_id_offset = 1\n",
        "    image_np_with_detections = image_np.copy()\n",
        "\n",
        "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "                image_np_with_detections,\n",
        "                detections['detection_boxes'],\n",
        "                detections['detection_classes']+label_id_offset,\n",
        "                detections['detection_scores'],\n",
        "                category_index,\n",
        "                use_normalized_coordinates=True,\n",
        "                max_boxes_to_draw=5,\n",
        "                min_score_thresh=.8,\n",
        "                agnostic_mode=False)\n",
        "\n",
        "    cv2.imshow('object detection',  cv2.resize(image_np_with_detections, (800, 600)))\n",
        "\n",
        "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
        "        cap.release()\n",
        "        cv2.destroyAllWindows()\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5dM5ezIFR5k"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0gOhdmEFR5k"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8r_pqlfaFR5k"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7fjCJO9FR5l"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2A5sFVQFR5l"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bL5HXiMQFR5l"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cH8J0VPqFR5l"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "py9P8W1lFR5l"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oqx4W33qFR5l"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZmU7Sc8FR5l"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_NE_FpxQFR5l"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}